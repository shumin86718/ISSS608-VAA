[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Visual Analytics & Applications",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics & Applications!\nIn this Webpage, I am going to share with you my learning journey in Visual Analytics.\nModule page: VISUAL ANALYTICS & APPLICATIONS\nInstructor: Prof Kam Tin Seong\n\n\n\nLesson\nTopic\nDate\nExercises covered\n\n\n\n\n1\nIntroduction to Visual Analytics\n15/4\nHands-on Ex1\nIn-class Ex1\nSuperstore dashboard\n\n\n2\nDesigning Graphs to Enlighten\n29/4\nHands-on Ex2\n\n\n3\nInteractivity in Visual Analytics\n6/5\nHands-on Ex3-1\nHands-on Ex3-2\nIn-class Ex3\n\n\n4\nFundamentals of Visual Analytics\n13/5\n\n\n\n5\nVisual Multivariate Analysis\n20/5\n\n\n\n6\nIt’s About Time\n27/5\n\n\n\n7\nVisualising and Analysing Geographic Data\n3/6\n\n\n\n8\nNetwork Data Visualisation and Analysis\n10/6\n\n\n\n9\nInformation Dashboard Design\n17/6\n\n\n\n10\nVisual Analytics of Financial Data\n24/6"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "In this chapter, we will learn the basic principles and essential components of ggplot2. At the same time, we will gain hands-on experience in using these components to plot statistical graphics based on the principle of the Layered Grammar of Graphics."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.2 Getting started",
    "text": "1.2 Getting started\n\n1.2.1 Installing and loading the required libraries\n\npacman::p_load(tidyverse)\n\n\n\n1.2.2 Import Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\nskim( ) - skimr - to get an overview of a data frame with summarised statistics. For this usage, this function is used to identify missing values.\n\nskimr::skim(exam_data)\n\n\nData summary\n\n\nName\nexam_data\n\n\nNumber of rows\n322\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nID\n0\n1\n10\n10\n0\n322\n0\n\n\nCLASS\n0\n1\n2\n2\n0\n9\n0\n\n\nGENDER\n0\n1\n4\n6\n0\n2\n0\n\n\nRACE\n0\n1\n5\n7\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nENGLISH\n0\n1\n67.18\n14.69\n21\n59.00\n70\n78.00\n96\n▁▂▅▇▃\n\n\nMATHS\n0\n1\n69.33\n19.98\n9\n58.00\n74\n85.00\n99\n▁▂▃▇▇\n\n\nSCIENCE\n0\n1\n61.16\n18.18\n15\n49.25\n65\n74.75\n96\n▂▃▆▇▃"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#results",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#results",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Results",
    "text": "Results\n\nR Graphics\nWe show a scatter plot in this section.\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\nggplot2\nWe show the data in this tab.\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#introducing-ggplot",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#introducing-ggplot",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\nIt is an R package for declarative creating data-driven graphics based on The Grammar of Graphics. It is also part of the tidyverse family specially designed for visual exploration and communication.\n\nFor more detail, visit ggplot2 link.\n\n\n1.3.1 R Graphics vs ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR Graphicsggplot2\n\n\nWe show a histogram plot in this section.\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\nWe show the ggplot in this tab.\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#grammar-of-graphics",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#grammar-of-graphics",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\nBefore we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n1.4.1 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\nData: The dataset being plotted. Aesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency. Geometrics: The visual elements used for our data, such as point, bar or line. Facets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots). Statistics, statiscal transformations that summarise data (e.g. mean, confidence intervals). Coordinate systems define the plane on which data are mapped on the graphic. Themes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\ncall ggplot() function use below code chunk.\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.7 Essential Grammatical Elements in ggplot2: geom",
    "text": "1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n1.7.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar()\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n1.7.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\n`scale_y_continuous()` is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n1.7.3 Geometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe default bin is 30.\n\n\n1.7.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n1.7.5 Modifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n1.7.6 Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\n\nkernel density estimatetwo kernel density linesfill with arguments\n\n\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = MATHS, \n           fill = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n1.7.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot()\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n1.7.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n1.7.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n1.7.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.8 Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n1.8.3 Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n1.8.4 Adding a best fit curve on a scatterplot?\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default method used is loess.\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n1.9.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n1.9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n-   [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\n-   [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped.\n-   [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a \"fixed\" aspect ratio (e.g. 1.78 for a \"widescreen\" plot).\n-   [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n1.10.1 Working with Coordinate\n\ndefault bar chartcoord_flip\n\n\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n1.10.2 Changing the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.11 Essential Grammatical Elements in ggplot2: themes",
    "text": "1.11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with theme\n\ntheme_graytheme_classictheme_minimal\n\n\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#reference",
    "href": "Hands-on_Exercies/Hands-on_Ex1/Hands-on_Ex1.html#reference",
    "title": "Hands-on Ex1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.12 Reference",
    "text": "1.12 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "In-class_Exercies/In-class_Ex1/In-class_Ex1.html",
    "href": "In-class_Exercies/In-class_Ex1/In-class_Ex1.html",
    "title": "In-class_Ex1",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nPlot a horizontal bar chart using theme().\nChanging the colors of plot panel background of theme_minimal() to light blue and the color of grid lines to white.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme(panel.background = element_rect(fill = \"lightblue\"),\n        panel.grid.major = element_line(color = \"white\"))\n\n\n\n\n\n\n\nThe original design, A simple vertical bar chart for frequency analysis. Critics:\ny-aixs label is not clear (i.e. count) To support effective comparison, the bars should be sorted by their resepctive frequencies. For static graph, frequency values should be added to provide addition information.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nWith reference to the critics on the earlier paragraph, create a makeover looks similar to the figure at below.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(after_stat(count), \", \", \n      round(after_stat(count)/sum(after_stat(count))*100, 1), \"%\")),\n      vjust=-1) +\n  theme(axis.title.y=element_text(angle = 0))\n\n\n\n\n\ngeom_text() adds text labels to the plot\nstat = \"count\" tells ggplot to calculate the count of each bar\naes(label = paste0(after_stat(count), \", \", round(after_stat(count)/sum(after_stat(count))*100, 1), \"%\")) maps the text label to a string that combines three pieces of information:\n\nafter_stat(count) calculates the count of each bar, after the stat = \"count\" argument has been applied to the data. This is equivalent to the ..count.. variable .\nround(after_stat(count)/sum(after_stat(count))*100, 1) calculates the percentage of each bar’s count relative to the total count, and rounds it to one decimal place. The sum(after_stat(count)) calculates the total count of all bars, after the stat = \"count\" argument has been applied to the data.\npaste0() combines the count and percentage values into a single string, separated by a comma and a space.\n\nvjust = -1 adjusts the vertical justification of the labels so that they appear above the top of each bar.\n\nMethod 2 This code chunk uses fct_infreq() of forcats package.\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\nmutate(RACE = fct_infreq(RACE)) sorts the levels of the RACE variable in descending order of frequency. The fct_infreq() function from the forcats package is used to reorder the levels.\n\n\n\nThe original design\n\nMakeover design\n\nAdding mean and median lines on the histogram plot.\nChange fill color and line color\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(MATHS)), color=\"red\", \n             linetype=\"dashed\", size=0.85) +\n  geom_vline(aes(xintercept=median(MATHS)), color=\"black\", \n             linetype=\"dashed\", size=0.85)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nThe original design\nThe histograms at below are elegantly designed but not informative. This is because they only reveal the distribution of English scores by gender but without context such as all pupils.\n\nggplot(data=exam_data, \n       aes(x= ENGLISH)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ GENDER)\n\n\n\n\nCreate a makeover looks similar to the figure below. The background histograms show the distribution of English scores for all pupils.\n\nd <- exam_data   \nd_bg <- d[, -3]  \n\nggplot(d, aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = d_bg, fill = \"grey\", alpha = .5) +\n  geom_histogram(colour = \"black\") +\n  facet_wrap(~ GENDER) +\n  guides(fill = FALSE) +  \n  theme_bw()\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe code first creates a copy of the original dataset called d, and then creates another copy called d_bg by removing the maths and science columns using the [ , -3] syntax. This is done because we want to create a histogram of ENGLISH scores for all pupils as a background to the histograms of male and female pupils.\nTwo geom_histogram() layers are added: the first one with the data argument set to d_bg, which creates a background histogram of ENGLISH scores for all pupils with a fill color of “grey” and an alpha value of 0.5 to make it semi-transparent. The second geom_histogram() layer creates a histogram of ENGLISH scores for male and female pupils separately, with black borders and default fill colors. The facet_wrap() function is used to create separate histograms for male and female pupils. Finally, the guides() function is used to remove the fill legend, and theme_bw() is used to set a black-and-white theme for the plot."
  },
  {
    "objectID": "In-class_Exercies/In-class_Ex1/In-class_Ex1.html#getting-started",
    "href": "In-class_Exercies/In-class_Ex1/In-class_Ex1.html#getting-started",
    "title": "In-class_Ex1",
    "section": "1.2 Getting started",
    "text": "1.2 Getting started\n\n1.2.1 Installing and loading the required libraries"
  },
  {
    "objectID": "In-class_Exercies/In-class_Ex1/In-class_Ex1.html#designing-data-drive-graphics-for-analysis-iv",
    "href": "In-class_Exercies/In-class_Ex1/In-class_Ex1.html#designing-data-drive-graphics-for-analysis-iv",
    "title": "In-class_Ex1",
    "section": "7 Designing Data-drive Graphics for Analysis IV",
    "text": "7 Designing Data-drive Graphics for Analysis IV\nThe original design\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()             \n\n\n\n\nCreate a makeover that looks similar to the figure below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  xlim(0,100) +\n  ylim(0,100) +\n  geom_hline(yintercept=50, color=\"red\", \n             linetype=\"dashed\", size=0.85) +\n  geom_vline(xintercept=50, color=\"black\", \n             linetype=\"dashed\", size=0.85) +\n  geom_point() \n\n\n\n\nThe xlim() and ylim() functions are used to set the limits of the x and y axes to 0-100, respectively.\nThe geom_hline() and geom_vline() functions are used to add a horizontal dashed line at y=50 with a red color and a vertical dashed line at x=50 with a black color, both with a line type of “dashed” and a size of 0.85. These lines represent the median score for each subject, i.e. the score at which half of the pupils scored higher and half scored lower."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html",
    "href": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html",
    "title": "Hands-on_Ex2 - Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "This chapter introduces you to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "href": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "title": "Hands-on_Ex2 - Beyond ggplot2 Fundamentals",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\n\n2.2.1 Installing and loading the required libraries\nBefore we get started, it is important for us to ensure that the required R packages have been installed. The chunk code will do the necessary package loading.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel) \n\n\n\n2.2.2 Importing data\nThe code chunk below imports exam_data.csv into R environment using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#beyond-ggplot2-annotation",
    "href": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#beyond-ggplot2-annotation",
    "title": "Hands-on_Ex2 - Beyond ggplot2 Fundamentals",
    "section": "2.3 Beyond ggplot2 Annotation",
    "text": "2.3 Beyond ggplot2 Annotation\nOne of the challenges in plotting statistical graphs is annotation, especially with a large number of data points.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n2.3.1 Working with ggrepel\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right. We simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#beyond-ggplot2-themes",
    "href": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#beyond-ggplot2-themes",
    "title": "Hands-on_Ex2 - Beyond ggplot2 Fundamentals",
    "section": "2.4 Beyond ggplot2 Themes",
    "text": "2.4 Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +  \n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\nRefer to this link to learn more about ggplot2 Themes\n\n2.4.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others. In the example below, The Economist theme is used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n2.4.2 Working with hrbthems\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family not\nfound in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family not\nfound in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family not\nfound in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family not\nfound in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#beyond-single-graph",
    "href": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#beyond-single-graph",
    "title": "Hands-on_Ex2 - Beyond ggplot2 Fundamentals",
    "section": "2.5 Beyond Single Graph",
    "text": "2.5 Beyond Single Graph\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\nPlotCode\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nNext\n\nPlotCode\n\n\n\nggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\n\n\n\np2 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below\n\nPlotCode\n\n\n\nggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n2.5.1 Creating Composite Graphics: pathwork methods \nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n2.5.2 Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\np1 + p2\n\n\n\n\n\n\n2.5.3 Combining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“|” operator to stack two ggplot2 graphs,\n“/” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n2.5.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np12 <- p1|p2\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\npatchwork <- (p1 / p2) | p3\npatchwork & theme_economist()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#code-2",
    "href": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#code-2",
    "title": "Hands-on_Ex2 - Beyond ggplot2 Fundamentals",
    "section": "Code",
    "text": "Code\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n:::"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#reference",
    "href": "Hands-on_Exercies/Hands-on_Ex2/Hands-on_Ex2.html#reference",
    "title": "Hands-on_Ex2 - Beyond ggplot2 Fundamentals",
    "section": "2.6 Reference",
    "text": "2.6 Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html",
    "title": "Hands-on Ex3 - Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "title": "Hands-on Ex3 - Programming Interactive Data Visualisation with R",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#importing-data",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#importing-data",
    "title": "Hands-on Ex3 - Programming Interactive Data Visualisation with R",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Ex3 - Programming Interactive Data Visualisation with R",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it is used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on the client and server sides. Refer to this article for a more detail explanation.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow is a typical code chunk to plot an interactive statistical graph using the ggiraph package. Notice that the code chunk consists of two parts.\nFirst, an ggplot object will be created.\nNext, girafe() of ggiraph will be used to create an interactive svg object.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, the basic graph will be created by an interactive version of ggplot2 geom (i.e.· geom_dotplot_interactive())geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\n\n\n\nInteractivity\n\n\n\nBy hovering the mouse pointer on a data point of interest, the student’s ID will be displayed.\n\n\n\n\n3.4.2 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip <- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as a tooltip field as shown in the code of line 7.\n\n\n\n\n\n\nInteractivity\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n3.4.3 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css <- \"background-color:white; #<<\nfont-style:bold; color:black;\" #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #<<\n    opts_tooltip(    #<<\n      css = tooltip_css)) #<<\n)                                        \n\n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n3.4.4 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip <- function(y, ymax, accuracy = .01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n3.4.5 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                       \n\n\n\n\n\n\n\n\n\n\n\nInteractivity\n\n\n\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n3.4.6 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nInteractivity\n\n\n\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\n\n3.4.7 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n3.4.8 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                       \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n3.4.9 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Ex3 - Programming Interactive Data Visualisation with R",
    "section": "3.5 Interactive Data Visualisation - plotly methods!",
    "text": "3.5 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.5.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n3.5.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n3.5.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n3.5.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nd <- highlight_key(exam_data)\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Ex3 - Programming Interactive Data Visualisation with R",
    "section": "3.6 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.6 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.6.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n3.6.2 Linked brushing: crosstalk method\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#reference",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3.html#reference",
    "title": "Hands-on Ex3 - Programming Interactive Data Visualisation with R",
    "section": "3.7 Reference",
    "text": "3.7 Reference\n\n3.7.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.7.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html",
    "title": "Hands-on Ex3 - 4 Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#getting-started",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#getting-started",
    "title": "Hands-on Ex3 - 4 Programming Animated Statistical Graphics with R",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Loading the R packages\nFirst, write a code chunk to check, install and launch the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n4.2.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %>%\n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nTip\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Ex3 - 4 Programming Animated Statistical Graphics with R",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n4.3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n4.3.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#animated-data-visualisation-plotly",
    "title": "Hands-on Ex3 - 4 Programming Animated Statistical Graphics with R",
    "section": "4.4 Animated Data Visualisation: plotly",
    "text": "4.4 Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n4.4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\ngg <- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from above code chunk\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\n\n\n4.4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp <- globalPop %>%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent, \n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %>%\n  layout(xaxis = list(showgrid = TRUE, gridcolor = 'lightgrey', gridwidth = 0.5),\n         yaxis = list(showgrid = TRUE, gridcolor = 'lightgrey', gridwidth = 0.5))\n  \nbp"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#reference",
    "href": "Hands-on_Exercies/Hands-on_Ex3/Hands-on_Ex3-2.html#reference",
    "title": "Hands-on Ex3 - 4 Programming Animated Statistical Graphics with R",
    "section": "4.5 Reference",
    "text": "4.5 Reference\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html",
    "href": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html",
    "title": "Take-home Exercise 1 - Putting Visual Analytics into Practical Use",
    "section": "",
    "text": "In this take-home exercise, we are required to apply the concepts and methods learned in Lesson 1-4 to reveal the demographic and financial characteristics of the city of Engagement, using appropriate static and interactive statistical graphics methods. This exercise requires a user-friendly and interactive solution that helps city managers and planners to explore complex data in an engaging way and reveal hidden patterns. The data should be processed by using the appropriate tidyverse family of packages and the statistical graphics must be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#data-preparation",
    "href": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#data-preparation",
    "title": "Take-home Exercise 1 - Putting Visual Analytics into Practical Use",
    "section": "2. Data Preparation",
    "text": "2. Data Preparation\n\n2.1 Installing and loading the required libraries\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\n\nShow the code\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse, dplyr, gganimate, ggridges, ggplot2, ggstatsplot, cowplot, ragg, ungeviz, ggdist, ggside, viridis) \n\n\n\n\n2.2 Importing Data\nThe code chunk below read_csv() of readr package is used to import Participants.csv & FinancialJournal.csv data file into R and save it as an tibble data frame called participants & financial.\n\n\nShow the code\nparticipants <- read_csv(\"data/participants.csv\")\nfinancial <- read_csv(\"data/financialJournal.csv\")\n\n\n\n\n2.3 Data Preperation\nwe will examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(participants)\n\n\nRows: 1,011\nColumns: 7\n$ participantId  <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ householdSize  <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ haveKids       <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n$ age            <dbl> 36, 25, 35, 21, 43, 32, 26, 27, 20, 35, 48, 27, 34, 18,…\n$ educationLevel <chr> \"HighSchoolOrCollege\", \"HighSchoolOrCollege\", \"HighScho…\n$ interestGroup  <chr> \"H\", \"B\", \"A\", \"I\", \"H\", \"D\", \"I\", \"A\", \"G\", \"D\", \"D\", …\n$ joviality      <dbl> 0.001626703, 0.328086500, 0.393469590, 0.138063446, 0.8…\n\n\n\n\nShow the code\nglimpse(financial)\n\n\nRows: 1,513,636\nColumns: 4\n$ participantId <dbl> 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6,…\n$ timestamp     <dttm> 2022-03-01, 2022-03-01, 2022-03-01, 2022-03-01, 2022-03…\n$ category      <chr> \"Wage\", \"Shelter\", \"Education\", \"Wage\", \"Shelter\", \"Educ…\n$ amount        <dbl> 2472.50756, -554.98862, -38.00538, 2046.56221, -554.9886…\n\n\nThe code chunk below will be used to perform the missing value checking.\n\n\nShow the code\n#Check for missing values\nany(is.na(participants))\n\n\n[1] FALSE\n\n\nShow the code\nany(is.na(financial))\n\n\n[1] FALSE\n\n\n\n\n\n\n\n\n\n\nIssues\nDescription\nResolution\n\n\n\n\ntimestamp\nSome rows have time data while some rows don’t.\nAs the time data doesn’t help with the analysis, we should exclude the time data, leave only the date. And extract month to create month variable.\n\n\nData Duplicates\nDuplicate entries for Education and Shelter expenses on 1st March 2022\nRemove the duplicates\n\n\nIncompleted records for a specific group of participants\nThere are 131 participants who had only March expenses, which may indicate they no longer lived in the town\nRemove 131 participants from the merged dataframe\n\n\nInappropriate table format\nExpenses and income are aggregated in one category variable\nTranspose the amount of expense and income to individual variable labeled by the category for financial table\n\n\nTable merge\nThe participants data and fanciancial data are in two tables\nFor ease data analysis, we should merge two tables together and grouped the records by participantId and month\n\n\nNew variables create\nCreate expenditures and savings for participants financial health analysis\nExpenditures should includes Education, Food, Recreation, Shelter cost.\nSavings should be Wage minus the expenditures.\n\n\n\nBelow code chunks will work on the above data issues and create the final merged dataframe merged_T.\n\n\nShow the code\n#convert timestamp to date type and extract yearmonth variable\nfinancial <- financial %>%\n  mutate(date= as.Date(timestamp)) %>%\n  mutate(yearmonth = format(financial$timestamp, \"%Y-%m\"))\n\n\n# remove duplicated rows\nfinancial <- distinct(financial) %>%\n  select(-timestamp) %>%  #remove timestamp column\n  \n  # group data by participantId, yearmonth and category of expenses\n  group_by(participantId, yearmonth, category) %>%  \n  \n  # to create total_amount by summerize the amount from each category, convert the amount of expenditures to positive nums\n    summarise(total_amount = sum(amount)) %>% \n  mutate(abs_amount = abs(total_amount))\n\n#create month variable and convert to integer\nfinancial$month <- as.integer(substr(financial$yearmonth, 6, 7))\n#convert abs_amount as integer\nfinancial$abs_amount <- round(financial$abs_amount, 0)\n\n\n\n\nShow the code\n#transpose amount labeled by category \nfinancial_t <- financial %>%\n  select(-total_amount) %>%\n  pivot_wider(\n    names_from = category,\n    values_from = abs_amount,\n    values_fn = sum,\n    values_fill = 0\n  ) %>%\n  select(-RentAdjustment) %>%  #remove RentAdjustment as it already accounted in March Shelter cost\n  \n  mutate(hourlyWage = round(Wage/(44*4)), 0) #based on weekly 44 hours working hours and a month has 4 weeks\n\nfinancial_t\n\n\n# A tibble: 10,691 × 10\n# Groups:   participantId, yearmonth [10,691]\n   participantId yearmonth month Education  Food Recreation Shelter  Wage\n           <dbl> <chr>     <int>     <dbl> <dbl>      <dbl>   <dbl> <dbl>\n 1             0 2022-03       3        38   268        349     555 11932\n 2             0 2022-04       4        38   266        219     555  8637\n 3             0 2022-05       5        38   265        383     555  9048\n 4             0 2022-06       6        38   257        466     555  9048\n 5             0 2022-07       7        38   270       1070     555  8637\n 6             0 2022-08       8        38   262        314     555  9459\n 7             0 2022-09       9        38   256        295     555  9048\n 8             0 2022-10      10        38   267         25     555  8637\n 9             0 2022-11      11        38   261        377     555  9048\n10             0 2022-12      12        38   266        357     555  9048\n# ℹ 10,681 more rows\n# ℹ 2 more variables: hourlyWage <dbl>, `0` <dbl>\n\n\n\n\nShow the code\n#Remove the 131 no. participants which only have March expenses\nfinancial_t_r <- financial_t[financial_t$Shelter != 0, ]\n\n\n\n\nShow the code\nmerged <- merge(participants, financial, by = \"participantId\", all = TRUE)\n\n\n#merge participantid and financial tables\nmerged_T <- merge(participants, financial_t_r, by = \"participantId\", all = FALSE) %>%\n  mutate(expenditure = Education + Food + Recreation + Shelter) %>%\n  mutate(savings = Wage - expenditure) %>%\n  select(participantId, yearmonth, month, householdSize, haveKids, age, educationLevel, joviality, Wage, hourlyWage, expenditure, savings, Education, Food, Recreation, Shelter)\n\n#convert joviality column as percentage and round to 2 decimal places\nmerged_T$joviality <- round(merged_T$joviality*100, 2)"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html",
    "href": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html",
    "title": "Hands-on_Ex4-1 Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on_Ex4-1 Visual Statistical Analysis",
    "section": "9.2 Visual Statistical Analysis with ggstatsplot",
    "text": "9.2 Visual Statistical Analysis with ggstatsplot\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#getting-started",
    "href": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#getting-started",
    "title": "Hands-on_Ex4-1 Visual Statistical Analysis",
    "section": "9.3 Getting Started",
    "text": "9.3 Getting Started\n\n9.3.1 Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n9.3.2 Importing data\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\n\n9.3.3 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n9.3.4 Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n9.3.5 How to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n9.3.6 Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n9.3.7 Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n9.3.7.1 ggbetweenstats - Summary of tests\n\n\n\n\n\n\n9.3.8 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n9.3.9 Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#visualising-models",
    "href": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#visualising-models",
    "title": "Hands-on_Ex4-1 Visual Statistical Analysis",
    "section": "9.4 Visualising Models",
    "text": "9.4 Visualising Models\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#getting-started-1",
    "href": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#getting-started-1",
    "title": "Hands-on_Ex4-1 Visual Statistical Analysis",
    "section": "9.5 Getting Started",
    "text": "9.5 Getting Started"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-1.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on_Ex4-1 Visual Statistical Analysis",
    "section": "9.6 Installing and loading the required libraries",
    "text": "9.6 Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n9.6.1 Importing Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   <dbl> <chr>    <dbl>     <dbl>     <dbl>    <dbl>  <dbl>         <dbl>  <dbl>\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period <dbl>, HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n9.6.2 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n9.6.3 Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n9.6.4 Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n9.6.5 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n9.6.6 Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n9.6.7 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n9.6.8 Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-2.html#visualizing-the-uncertainty-of-point-estimates",
    "href": "Hands-on_Exercies/Hands-on_Ex4/Hands-on_Ex4-2.html#visualizing-the-uncertainty-of-point-estimates",
    "title": "Hands-on_Ex4-2 Visualising Uncertainty",
    "section": "10.2 Visualizing the uncertainty of point estimates",
    "text": "10.2 Visualizing the uncertainty of point estimates\n\nA point estimate is a single number, such as a mean.\nUncertainty is expressed as standard error, confidence interval, or credible interval\nImportant:\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate, ggplot2, dplyr)\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\n10.2.1 Visualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nNote: For the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\n10.2.2 Visualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below is used to reveal the standard error of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n10.2.3 Visualizing the uncertainty of point estimates: ggplot2 methods\n\nmy_sum_sorted <- my_sum %>% \n  arrange(desc(mean)) %>%\n  mutate(RACE = forcats::fct_reorder(RACE, -mean))\n\n\nggplot(my_sum_sorted) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")"
  },
  {
    "objectID": "In-class_Exercies/In-class_Ex4/In-class_Ex4.html",
    "href": "In-class_Exercies/In-class_Ex4/In-class_Ex4.html",
    "title": "In-class_Ex4",
    "section": "",
    "text": "Installing and launching R packages\n\npacman::p_load(rstatix, gt, patchwork, tidyverse, webshot2, png)\n\n\n\nImporting the dataset\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nVisualising Normal Distribution\nQ-Q plot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n       aes(sample=ENGLISH)) + \n  stat_qq() +\n  stat_qq_line(color=\"red\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed.\n\n\n\n\nCombining statistical graph and analysis table\nNeed to install webshot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nqq <- ggplot(exam_data,\n             aes(sample=ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t, tmp)\ntable_png <- png::readPNG(tmp, native =TRUE)\n\nqq + table_png"
  },
  {
    "objectID": "In-class_Exercies/In-class_Ex4/In-class_Ex4.html#the-code",
    "href": "In-class_Exercies/In-class_Ex4/In-class_Ex4.html#the-code",
    "title": "In-class_Ex4",
    "section": "The code",
    "text": "The code\n\nqq <- ggplot(exam_data,\n             aes(sample=ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t, tmp)\ntable_png <- png::readPNG(tmp, native =TRUE)\n\nqq + table_png"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#visualising-uncertainty",
    "href": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#visualising-uncertainty",
    "title": "Take-home_Ex1",
    "section": "Visualising Uncertainty",
    "text": "Visualising Uncertainty\n\n\nShow the code\nggplot(data = merged_T, \n       (aes(x = factor(educationLevel), y = Wage))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = educationLevel), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\nShow the code\nggplot(data = merged_T, \n                    aes(x = householdSize, y = Food)) +\nstat_pointinterval(point_interval = \"median_qi\",\n                   .width = c(0.95,0.99),\n                   point_color = \"lightpink4\") +\nlabs(title = \"Household size vs Food\", x = \"household size\", y = \"Food expenditure\") + \ntheme(axis.text.x = element_text(angle = 0, vjust = 1, hjust=1)) +\nscale_y_continuous(limits = c(0, 500))\n\n\n\n\n\n\n\nShow the code\nmerged_T %>%\n  ggplot(aes(x = householdSize, \n             y = Wage)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean Income\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\nSignificant Test of Correlation: Food and Income\n\n\nShow the code\nggscatterstats(\n  data = merged_T,\n  x = Food,\n  y = Wage,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nSignificant Test of Correlation: joviality and Recreation\n\n\nShow the code\nggscatterstats(\n  data = merged_T,\n  x = Recreation,\n  y = joviality,\n  marginal = FALSE,\n  type = \"nonparametric\"\n  )\n\n\n\n\n\n\n\nShow the code\nggscatterstats(data = merged_T, \n                           x = Recreation, y = joviality,\n                           type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  labs(title = \"Recreation vs joviality\", \n       x = \"Recreation\", y = \"joviality\") +\n  scale_x_continuous(limits = c(0, 2000)) +\n  scale_y_continuous(limits = c(0, 1))\n\n\n\n\n\n\n\nShow the code\nggscatterstats(data = merged_T, \n                           x = joviality, y = Wage,\n                           type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  labs(title = \"joviality vs Wage\", \n       x = \"joviality\", y = \"Wage\") +\n  scale_x_continuous(limits = c(0, 1)) +\n  scale_y_continuous(limits = c(0, 25000))\n\n\n\n\n\n\n\nSignificant Test of Association (Depedence) : ggbarstats() methods\nhaveKids vs Wage\n\n\nShow the code\nmerged_T1 <- merged_T %>% \n  mutate(wage_bins = \n               cut(Wage, \n               breaks = quantile(Wage, probs = c(0, 0.25, 0.5, 0.75, 1)),\n               include.lowest = TRUE,\n               labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")))\n\nggbarstats(merged_T1, \n           x = wage_bins, \n           y = haveKids)"
  },
  {
    "objectID": "In-class_Exercies/In-class_Ex5/In-class_Ex5.html",
    "href": "In-class_Exercies/In-class_Ex5/In-class_Ex5.html",
    "title": "In-class_Ex5",
    "section": "",
    "text": "Installing and launching R packages\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\nImporting the dataset\n\n\nShow the code\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nReviewing the imported data\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\nBuilding Interactive Network Graph with visNetwork\n\nData preparation\n\n\nShow the code\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n\nPlotting the first interactive network graph\n\n\nShow the code\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\n\nWorking with visual attributes - Nodes\n\n\nShow the code\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "VAST2023/MC1/MC1.html",
    "href": "VAST2023/MC1/MC1.html",
    "title": "MC1",
    "section": "",
    "text": "Show the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, tidyverse)\n\n\n\n\nShow the code\nMC1 <- fromJSON(\"data/MC1.json\")\n\n\n\n\nShow the code\nMC1_nodes <- as_tibble(MC1$nodes) %>%\n  select(id, type, country)\n\n\n\n\nShow the code\nMC1_edges <- as_tibble(MC1$links) %>%\n  select(source, target, type, weight, key)"
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex5/Hands-on_Ex5.html",
    "href": "Hands-on_Exercies/Hands-on_Ex5/Hands-on_Ex5.html",
    "title": "Hands-on_Ex5",
    "section": "",
    "text": "Installing and launching R packages\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\npackage 'clock' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Shumin\\AppData\\Local\\Temp\\RtmpeO9fSc\\downloaded_packages\n\n\n\n\nImporting the dataset\n\n\nShow the code\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nReviewing the imported data\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\nBuilding Interactive Network Graph with visNetwork\n\nData preparation\n\n\nShow the code\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n\nPlotting the first interactive network graph\n\n\nShow the code\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\n\nWorking with visual attributes - Nodes\n\n\nShow the code\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#data-visulisation",
    "href": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#data-visulisation",
    "title": "Take-home Exercise 1 - Putting Visual Analytics into Practical Use",
    "section": "3. Data Visulisation",
    "text": "3. Data Visulisation\n\n3.1 Visualising Distribution for Income and Expenditure\n\n\nShow the code\n#computing summary statistics of mean, median and lower and upper whiskers in boxplot\nwage_mean <- round(mean(merged_T$Wage))\nwage_median <- round(median(merged_T$Wage))\nymax <- as.numeric(round((IQR(merged_T$Wage)*1.5) +\n                quantile(merged_T$Wage,0.75)))\nymin <- as.integer(min(merged_T$Wage))\n\n#plotting histogram\nh <- ggplot(data = merged_T, aes(x = Wage)) + \n  geom_histogram(color=\"black\", fill=\"azure4\", binwidth = 300) + \n  scale_x_continuous(limits = c(0,20000), labels = scales::comma) +\n  labs(x = \"Income\", y = \"Number of transactions\") +\n  geom_vline(aes(xintercept = wage_mean), col=\"darkblue\", linewidth=1) +\n  annotate(\"text\", x=5500, y=1150, label=\"Mean wage:\", \n           size=3, color=\"darkblue\") +\n  annotate(\"text\", x=5500, y=1100, label=format(wage_mean, big.mark = \",\"),\n           size=3, color=\"darkblue\") +\n  geom_vline(aes(xintercept = wage_median), col=\"lightpink4\", linewidth=1) +\n  annotate(\"text\", x=2200, y=1150, label=\"Median wage\", \n           size=3, color=\"lightpink4\") +\n  annotate(\"text\", x=2200, y=1100, label=format(wage_median, big.mark = \",\"),\n           size=3, color=\"lightpink4\") +\n  theme(axis.text.x = element_text(size=8))\n\n#plotting boxplot\nb <- ggplot(data = merged_T, aes(y = Wage)) + \n  geom_boxplot(outlier.colour=\"firebrick\", outlier.shape=12,\n               outlier.size=1, notch=FALSE) + \n  coord_flip() + labs(y = \"\", x = \"\") + \n  scale_y_continuous(limits = c(0,20000), labels = scales::comma) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank()) + \n  stat_boxplot(geom=\"errorbar\", width=0.5) + \n  annotate(\"text\", x=0.35, y=ymax, label=format(ymax, big.mark = \",\"), \n           size=3, color=\"lightpink4\") +\n  annotate(\"text\", x=0.35, y=ymin, label=format(ymin, big.mark = \",\"), \n           size=3, color=\"lightpink4\")\n\n#combining plots\nprice_distri <- b / h + plot_layout(heights = c(1, 4)) \n\nprice_distri + plot_annotation(title = \"Distribution of Income status\", \n                               subtitle = \"There is a right-skewed distribution \\ni.e. mean income > median income. There is also a large number of outliers (income >$9,166).\",\n                               theme = theme(\n                                 plot.title = element_text(size = 12),\n                                 plot.subtitle = element_text(size = 10)))\n\n\n\n\n\nThe Income plot shows right-skewed distribution, ie. mean income is larger than median income and there are large amount of outliers.\n\n\nShow the code\n#computing summary statistics of mean, median and lower and upper whiskers in boxplot\nexpense_mean <- round(mean(merged_T$expenditure))\nexpense_median <- round(median(merged_T$expenditure))\nymax <- as.numeric(round((IQR(merged_T$expenditure)*1.5) +\n                quantile(merged_T$expenditure,0.75)))\nymin <- as.integer(min(merged_T$expenditure))\n\n#plotting histogram\nh <- ggplot(data = merged_T, aes(x = expenditure)) + \n  geom_histogram(color=\"black\", fill=\"azure4\", binwidth = 50) + \n  scale_x_continuous(limits = c(0,5000), labels = scales::comma) +\n  labs(x = \"Expenditure\", y = \"Number of transactions\") +\n  geom_vline(aes(xintercept = expense_mean), col=\"darkblue\", linewidth=1) +\n  annotate(\"text\", x=1000, y=750, label=\"Mean expense:\", \n           size=3, color=\"darkblue\") +\n  annotate(\"text\", x=1000, y=710, label=format(expense_mean, big.mark = \",\"),\n           size=3, color=\"darkblue\") +\n  geom_vline(aes(xintercept = expense_median), col=\"lightpink4\", linewidth=1) +\n  annotate(\"text\", x=2000, y=750, label=\"Median expense\", \n           size=3, color=\"lightpink4\") +\n  annotate(\"text\", x=2000, y=710, label=format(expense_median, big.mark = \",\"),\n           size=3, color=\"lightpink4\") +\n  theme(axis.text.x = element_text(size=8))\n\n#plotting boxplot\nb <- ggplot(data = merged_T, aes(y = expenditure)) + \n  geom_boxplot(outlier.colour=\"firebrick\", outlier.shape=12,\n               outlier.size=1, notch=FALSE) + \n  coord_flip() + labs(y = \"\", x = \"\") + \n  scale_y_continuous(limits = c(0,5000), labels = scales::comma) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank()) + \n  stat_boxplot(geom=\"errorbar\", width=0.5) + \n  annotate(\"text\", x=0.35, y=ymax, label=format(ymax, big.mark = \",\"), \n           size=3, color=\"lightpink4\") +\n  annotate(\"text\", x=0.35, y=ymin, label=format(ymin, big.mark = \",\"), \n           size=3, color=\"lightpink4\")\n\n#combining plots\nprice_distri <- b / h + plot_layout(heights = c(1, 4)) \n\nprice_distri + plot_annotation(title = \"Distribution of Expenditure status\", \n                               subtitle = \"The plot doesn't show normally distribution \\n although mean and median are nearly the same. There is also a large number of outliers (income >$2,360).\",\n                               theme = theme(\n                                 plot.title = element_text(size = 12),\n                                 plot.subtitle = element_text(size = 10)))\n\n\n\n\n\nAlso the mean and median of the expenditures are nearly the same, however the disturbition plot does not show normally distribution, and there are large amount of outliers as well.\n\n\n3.2 Confirmatory Test for Normality\nTo use the one-sample test in gghistostats() to test if the numerical variables are normally distributed, we set the type argument to “shapiro”.\n\n\nShow the code\nset.seed(1234)\n\n#need to change bar colors, line color, ggtitles, gglabs\n\np1 <- gghistostats(\n  data = merged_T,\n  x = joviality,\n  type = \"shapiro\",\n  test.value = 0.6,\n  xlab = \"Joviality\") +\n  \n  theme_minimal() +\n  \n  theme(text = element_text(family = \"Garamond\"))\n        \np2 <- gghistostats(\n  data = merged_T,\n  x = Wage,\n  type = \"shapiro\",\n  test.value = 60,\n  xlab = \"Wage\"\n) +\n  theme_minimal() +\n  \n  theme(text = element_text(family = \"Garamond\"))\n\np3 <- gghistostats(\n  data = merged_T,\n  x = expenditure,\n  type = \"shapiro\",\n  test.value = 550,\n  xlab = \"Expenditure\"\n) +\n  theme_minimal() +\n  \n  theme(text = element_text(family = \"Garamond\"))\n\np4 <- gghistostats(\n  data = merged_T,\n  x = savings,\n  type = \"shapiro\",\n  test.value = 1000,\n  xlab = \"Savings\"\n) +\n  theme_minimal()+\n  \n  theme(text = element_text(family = \"Garamond\"))\n\n\n\nplot_grid(p1, p2, p3, p4, ncol = 2)\n\n\n\n\n\nShapiro-Wilk test statistics have all 4 numbers of p value <0.05 within the 95% CI level for Joviality, Wage, Expenditure and savings, this suggests that there is enough statistically evidence to confirm the distributions for above numerical variables are not normally distributed.\n\n\n3.3 Median expense, savings and Income change over time\n\n\nShow the code\nfin_stats <- merged %>%\n  group_by(category, month) %>%\n  mutate(transaction_n = n()) %>%\n  mutate(median_amount = median(abs_amount)) %>%\n  select(category, transaction_n, median_amount, month) %>%\n  distinct() %>%\n  arrange(category)\n\nggplot(fin_stats, aes(x = category, y = median_amount, \n                      size = transaction_n, \n                      colour = category)) +\n  geom_point(alpha = 0.7, show.legend = T) +\n  scale_size(range = c(2, 12)) +\n  labs(title = \"Median expsense and wage over time (2022-03 to 2023-02)\",\n       subtitle = \"Month: {as.integer(frame_time)}\", \n       x = \"Expenses and Wage\", y = \"Amount\",\n       size = \"No. of Transactions\", color = \"category\") +\n  transition_time(as.integer(month)) +\n  ease_aes('linear') + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),\n        title = element_text(size = 12)) + \n  scale_y_continuous(limits = c(25,7500))\n\n\n\n\n\nFrom the plot, we can observe that median expenses on education and food are the least and are stable throughout the year. Spending for recreation are in between shelter and other expenditures, and has higher spending during the month of March. The median Income is generally stable expect in the month of March which is almost doubled than rest of the months.\n\n\n3.5 Education Level\n\n3.5.1 Education Level vs Income\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on Wage by Education Level (non-parametric since we had known Wage is not normally distributed).\n\n\nShow the code\n#plotting violin plot across wage\n\nggbetweenstats(\n  data = merged_T,\n  x = educationLevel, \n  y = Wage,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\nFrom the Oneway Anova Test results, we observe that 4 different education levels have a higher number of significantly different relationships. This shows that there are indeed differences in Income status in each education levels.\nThe box plot shows that mediBacheloran income for residences with high education levels (Graduate, Bachelors) are higher than Low and high school or College levels.\n\n\n3.5.2 Education Level vs Expenditure\n\nEducation LevelGraduateBachelorsHighSchoolOrCollegeLow\n\n\n\n\nShow the code\nggplot(na.omit(merged_T),aes(x = educationLevel, y = expenditure)) +\n  \n  geom_boxplot(aes(fill = as.factor(month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"median\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly expenditure by Education Level\",\n       y = \"Expenditure\",\n       x = \"Education Level\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nShow the code\nna.omit(merged_T) %>% \n  filter(educationLevel == \"Graduate\") %>% \n  ggplot(aes(x = educationLevel, y = expenditure)) +\n  \n  geom_boxplot(aes(fill = as.factor(month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"median\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly expenditure by Graduate\",\n       y = \"Expenditure\",\n       x = \"Education Level\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nShow the code\n# Bachelors\nna.omit(merged_T) %>% \n  filter(educationLevel == \"Bachelors\") %>% \n  ggplot(aes(x = educationLevel, y = expenditure)) +\n  \n  geom_boxplot(aes(fill = as.factor(month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"median\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly expenditure by Bachelors\",\n       y = \"Expenditure\",\n       x = \"Education Level\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nShow the code\n# Bachelors\nna.omit(merged_T) %>% \n  filter(educationLevel == \"HighSchoolOrCollege\") %>% \n  ggplot(aes(x = educationLevel, y = expenditure)) +\n  \n  geom_boxplot(aes(fill = as.factor(month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"median\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly expenditure by HighSchoolOrCollege\",\n       y = \"Expenditure\",\n       x = \"Education Level\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nShow the code\n# Bachelors\nna.omit(merged_T) %>% \n  filter(educationLevel == \"Low\") %>% \n  ggplot(aes(x = educationLevel, y = expenditure)) +\n  \n  geom_boxplot(aes(fill = as.factor(month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"median\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly expenditure by Low\",\n       y = \"Expenditure\",\n       x = \"Education Level\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\nThe best metric for comparison over time and distribution is the median (they are unaffected by outliers). In the graph above, we observe that there is no discernible difference in the median expenditures for 4 education levels. However, we observed expenses in March are higher than the rest of the time across all education levels.\n\n\n3.5.2 Visualising Uncertainty of median Income by Education Level\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of Income by Education Level\n\n\nShow the code\nmerged_T %>%\n  ggplot(aes(x = educationLevel, \n             y = Wage)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean Income\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\nAs shown above, income have higher uncertainties on higher education level eg. Gradute and Bachelors. This could be potentially due to large presence of outliers in both education levels. On the opposite side, income for medium and low education level have lower uncertainties, which might indicate lower presence of outliers.\n\n\n\n3.6 Joviality\n\n3.6.1 Significant Test of Correlation: joviality and wage by having Kids\n\n\nShow the code\nf1 <- merged_T %>% \n  filter(haveKids == TRUE) %>%\n  ggscatterstats(x = joviality, y = Wage, \n                 type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  labs(title = \"joviality vs Wage (Have Kids)\", \n       x = \"joviality\", y = \"Wage\") +\n  scale_x_continuous(limits = c(0, 100)) +\n  scale_y_continuous(limits = c(0, 25000))\n\nf2 <- merged_T %>% \n  filter(haveKids == FALSE) %>%\n  ggscatterstats(x = joviality, y = Wage, \n                 type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  labs(title = \"joviality vs Wage (No Kids)\", \n       x = \"joviality\", y = \"Wage\") +\n  scale_x_continuous(limits = c(0, 100)) +\n  scale_y_continuous(limits = c(0, 25000))\n\nplot_grid(f1, f2, ncol = 1)\n\n\n\n\n\nThe correlation chart shows that there is a weak negative relationship (less than -0.5) between the joviality and Income level by having kids or not. The observation indicates that wealth does not unequivocally increase happiness. however, it is turned another way round. And between having or not having kids, the correlation relationship don’t have very much differences.\n\n\n3.6.2 Significant Test of Correlation: joviality and expenditure by househould size\n\n\nShow the code\nj1 <- merged_T %>% \n  filter(householdSize == 1) %>%\n  ggscatterstats(x = joviality, y = expenditure,\n                             type = \"nonparametric\") + \n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),\n            plot.title = element_text(size = 10, face = \"bold\")) +\n    labs(title = \"joviality vs Expenditure for household size 1\", \n         x = \"joviality\", y = \"Wage\") +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_y_continuous(limits = c(0, 5000))\n\nj2 <- merged_T %>% \n  filter(householdSize == 2) %>%\n  ggscatterstats(x = joviality, y = expenditure,\n                             type = \"nonparametric\") + \n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),\n            plot.title = element_text(size = 10, face = \"bold\")) +\n    labs(title = \"joviality vs Expenditure for household size 2\", \n         x = \"joviality\", y = \"Wage\") +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_y_continuous(limits = c(0, 5000))\n\nj3 <- merged_T %>% \n  filter(householdSize == 3) %>%\n  ggscatterstats(x = joviality, y = expenditure,\n                             type = \"nonparametric\") + \n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), plot.title = element_text(size = 10, face = \"bold\")) +\n    labs(title = \"joviality vs Expenditure for household size 3\", \n         x = \"joviality\", y = \"Wage\") +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_y_continuous(limits = c(0, 5000))\n\nplot_grid(j1, j2, j3, ncol = 1)\n\n\n\n\n\nThe correlation chart shows that there is a strong positive relationship (more than 0.5) between the joviality and Expenditure level by the household sizes. The observation indicates that as joviality increases, the expenditure level tends to increase as well. This indicates that households with higher levels of joviality tend to have higher expenditure levels. And between the different sizes of household, the correlation relationship has higher value for household size 2 category."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#conclusion-and-recommendation",
    "href": "Take-home_Exercise/Take-home_Ex1/Take-home_Ex1.html#conclusion-and-recommendation",
    "title": "Take-home Exercise 1 - Putting Visual Analytics into Practical Use",
    "section": "Conclusion and Recommendation",
    "text": "Conclusion and Recommendation\nThe following interpretations and recommendations are made:\n\nFamily with higher education level had income earned more than medium and low education level families. Educational grants can be considered to allocate to families with difficulties paying their education expenses.\nLow wages earned by Low education level residents; study grants can be set to encourage adult learners who would like to pursue continuity study.\nOur Visulasation shows the findings which indicate wealth does not unequivocally increase happiness, however, it is turned another way round."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html",
    "title": "Take-home_Ex2",
    "section": "",
    "text": "With reference to Mini-Challenge 2 of VAST Challenge 2023 and by using appropriate static and interactive statistical graphics methods, I will be revealing the:\n\nUse visual analytics to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns if any.\n\n\n\n\nTo analyse the temporal patterns, timeline visualization and network visualization will be used to identify the patterns and explore the possible the business relationship between entities.\nVisualizing Temporal Patterns:\nTimeline Visualization: Create a timeline visualization that shows the activities of companies over time. Each company can be represented as a separate entity on the timeline, and their fishing activities (both legal and illegal) can be displayed as events or bars. This allows analysts to compare the temporal patterns of different companies and identify any suspicious behavior or recurring patterns.\nTemporal Network Visualization:\nRepresent the relationships between companies and their fishing activities as a network, where nodes represent companies and edges indicate their fishing activities. By incorporating temporal information into the visualization, such as color-coding or varying the thickness of edges based on the time of occurrence or numbers of interactions between nodes, analysts can identify patterns of illegal fishing and observe if companies reappear under different names."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#install-and-load-the-packages",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#install-and-load-the-packages",
    "title": "Take-home_Ex2",
    "section": "Install and load the packages",
    "text": "Install and load the packages\nThe following code chunks will install and load the required packages.\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, tidyverse, igraph, ggiraph, ggplot2, ggthemes, patchwork, plotly, ggstatsplot, hrbrthemes)"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#load-the-dataset-in-json-format",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#load-the-dataset-in-json-format",
    "title": "Take-home_Ex2",
    "section": "Load the dataset in JSON format",
    "text": "Load the dataset in JSON format\nIn the code chunk below, from JSON() of jsonlite package is used to import mc2_challenge_graph.json into R environment.\n\n\nShow the code\nMC2 <- fromJSON(\"data/mc2_challenge_graph.json\")"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#data-wrangling",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#data-wrangling",
    "title": "Take-home_Ex2",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nExtracting the nodes and links\nThe code chunk is used to extract nodes/edges data tables from MC2 list object and save the output in a tibble data frame object called MC2_nodes and MC2_edges.\n\n\nShow the code\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  select(id, shpcountry, rcvcountry)\n\n\n\nMC2_edges <- as_tibble(MC2$links) %>%\n  mutate(Arrivaldate = ymd(arrivaldate)) %>%\n  mutate(year = year(Arrivaldate)) %>%\n  mutate(month = month(Arrivaldate)) %>%\n  select(source, target, Arrivaldate, year, month, hscode, valueofgoods_omu, volumeteu, weightkg, valueofgoodsusd) %>%\n  distinct()\n\n\n\nmutate() is used two times to create two derive fields.\nymd() of lubridate package is used to covert arrivaldate field from character data type into date data type.\nyear() of lubridate package is used to convert the values in ArrivalDate field into year values.\nmonth() of lubridate package is used to convert the values in ArrivalDate field into month values.\nselect() is used not only to select the field needed but also to re-organise the sequent of the fields.\n\n\n\nCheck for missing values\n\n\nShow the code\n#Check for missing values\nany(is.na(MC2_nodes))\n\n\n[1] TRUE\n\n\nShow the code\nany(is.na(MC2_edges))\n\n\n[1] TRUE\n\n\nShow the code\n# Calculate the percentage of NA values in each column\nnodes_na_pct <- colMeans(is.na(MC2_nodes)) * 100\n\n# Print the NA percentages\nprint(nodes_na_pct)\n\n\n        id shpcountry rcvcountry \n   0.00000   64.66624    8.41335 \n\n\nShow the code\n# Calculate the percentage of NA values in each column\nedges_na_pct <- colMeans(is.na(MC2_edges)) * 100\n\n# Print the NA percentages\nprint(edges_na_pct)\n\n\n          source           target      Arrivaldate             year \n         0.00000          0.00000          0.00000          0.00000 \n           month           hscode valueofgoods_omu        volumeteu \n         0.00000          0.00000         99.99471          9.38167 \n        weightkg  valueofgoodsusd \n         0.00000         54.36443 \n\n\nThe valueofgoods_omu has 99% of na values, therefore we can remove this variable from the edges table. In the nodes table, we have 64.6% and 8.4$ na values in shipping country and receiving country columns, we can replace the missing country names with “others”.\n\n\nShow the code\n#drop the valueofgoods_omu column, and remove rows with missing value in volumnteu column\nMC2_edges_clean <- MC2_edges[, -which(names(MC2_edges) == \"valueofgoods_omu\")]\n\nglimpse(MC2_edges_clean)\n\n\nRows: 5,309,087\nColumns: 9\n$ source          <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son'…\n$ target          <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica Ma…\n$ Arrivaldate     <date> 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028-…\n$ year            <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028, …\n$ month           <dbl> 2, 3, 2, 2, 9, 10, 4, 6, 9, 9, 2, 2, 4, 4, 3, 9, 3, 3,…\n$ hscode          <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"470…\n$ volumeteu       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ weightkg        <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, 6…\n$ valueofgoodsusd <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 586…\n\n\nShow the code\n# replace na with others in shipping country and receive country\nMC2_nodes_clean <- dplyr::mutate(MC2_nodes, \n                                shpcountry = ifelse(is.na(shpcountry), \"others\", shpcountry),\n                                rcvcountry = ifelse(is.na(rcvcountry), \"others\", rcvcountry))\n\nglimpse(MC2_nodes_clean)\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", \"others\", \"Oceanus\", \"others\", \"Oceanus\", \"Kon…\n$ rcvcountry <chr> \"Oceanus\", \"others\", \"Oceanus\", \"others\", \"Oceanus\", \"Utopo…\n\n\n\n\nHSCODE Mapping\nFrom the VAST MC2 datanotes we know that Harmonized System code for the shipment can be joined with the hscodes table to get additional details.\nThe hscode table used in this exercise was extracted from the World Customs Organization website.\n\nThe hscode system is used by more than 200 countries, it comprises more than 5000 commodity groups, each identified by a first six digit code. Generally, the first six digits of the HS code are the same in all countries. Different countries, however, may add further digits to detail commodities in more detail without amending the first six digits. In this exercise, as we will be only interested in the fish/seafood products. In hscode system, Fish and crustaceans, molluscs and other aquatic invertebrates etc. start with 301 to 309. Therefore, we will map the hscode to each type of fish products by identify the first 3 digits.\n\n\nShow the code\nMC2_edges_clean_mapped <- MC2_edges_clean %>%\n  mutate(fishtype = case_when(\n    startsWith(hscode, \"301\") ~ \"live fish\",\n    startsWith(hscode, \"302\") ~ \"fresh fish\",\n    startsWith(hscode, \"303\") ~ \"frozen fish\",\n    startsWith(hscode, \"304\") ~ \"fish meat\",\n    startsWith(hscode, \"305\") ~ \"processed fish\",\n    startsWith(hscode, \"306\") ~ \"crustaceans\",  #like lobster or shrimps\n    startsWith(hscode, \"307\") ~ \"molluscs\",  #like Oysters or Abalone\n    startsWith(hscode, \"308\") ~ \"aquatic invertebrates\", #like Sea cucumbers?\n    startsWith(hscode, \"309\") ~ \"seafood flours\",  #fish powder, shrimp powder?\n    TRUE ~ \"not fish\"\n  ))"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#visualization",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r.html#visualization",
    "title": "Take-home_Ex2",
    "section": "Visualization",
    "text": "Visualization\n\nVisualising Nodes Distribution\n\n\nShow the code\nsource_nodes_g <- MC2_nodes_clean %>%\n  left_join(MC2_edges_clean_mapped %>% select(source, fishtype), by = c(\"id\" = \"source\")) %>%\n  select(id, fishtype)\n\nsource_nodes_g <- source_nodes_g %>%\n  count(fishtype) %>%\n  arrange(n) %>%\n  mutate(fishtype = factor(fishtype, levels = fishtype))\n\nsource_nodes_g <- source_nodes_g %>%\n  plot_ly(x = ~reorder(fishtype, n), # Reorder the x-axis categories based on count\n          y = ~n, \n          type = \"bar\", \n          color = I('#808de8'), \n          text = ~n, \n          textposition = \"auto\", \n          hoverinfo = \"text\", # Set hover information to display text\n          texttemplate = \"%{y}\"\n          ) %>%\n  layout(\n    title = list(text = \"Distribution of source nodes by fishtype\", x = 0.5),\n    yaxis = list(title = \"No. of Companies\"),\n    xaxis = list(title = \"fishtype\", tickangle = -90),   # Set x-axis title and tick angle\n    showlegend = FALSE\n  )\n\nsource_nodes_g\n\n\n\n\n\n\nUpon evaluating the node distribution plot delineated by product type, it becomes clear that entities not related to the fish or seafood industries account for the majority of the data. Followed by ‘fish meat’, ‘crustaceans’, and ‘frozen fish’ in decreasing order.\nGiven our task is to analyze patterns among fishing companies, it would be prudent to narrow down our data set and filter out irrelevant noise. In this context, companies identified as ‘not fish’ that do not engage in fish or seafood related operations may skew the analysis and should be removed.\n\n\nTimeline Visualization\n\n\nShow the code\ngrp1 <- MC2_edges_clean_mapped %>%\n  group_by(year, month, fishtype) %>%\n  summarise(no_shnpment = n()) %>%\n  filter(fishtype != \"not fish\") %>%\n  ungroup()\n\ntt <- c(paste(\"Year:\", grp1$year, \"<br>Month:\", grp1$month, \"<br>fishtype:\", grp1$fishtype, \"<br>NoShipment:\", grp1$no_shnpment))\n\nfig1 <- grp1 %>%\n  mutate(month = factor(month, levels = 1:12, labels = 1:12)) %>%\n  ggplot(aes(x = month, y = no_shnpment, fill = fishtype, text = tt)) +\n  geom_bar(position = \"stack\", stat = \"identity\") +\n  scale_fill_viridis(discrete = TRUE) +\n  labs(title = \"No of shipment per month, 2028 - 2034\", x = 'Month', y = 'No of shipment') +\n  theme(legend.position = \"none\") +\n  xlab(\"\") +\n  scale_x_discrete(labels = 1:12)\n\nfig1 <- ggplotly(fig1, tooltip = \"text\")\n\n# Create subplot layout\nsubplot <- subplot(fig1, nrows = 1, shareX = TRUE)\n\nsubplot\n\n\n\n\n\n\nWe examined above plot of the monthly shipment count, organized by fish type (excluding non-fish products), revealed distinct temporal patterns. Notably a dip in shipments was observed in April, followed by a gradually raising trend to a peak in October. This is then succeeded stable trend in November and December, suggesting a stabilization of activity during these months.\nSuch patterns could be attributed to the majority of fisheries operating in accordance with seasonal cycles, which affect the timing and intensity of their fishing activities. Consequently, our subsequent analyses will refine the focus to those months demonstrating higher fishing activities.\n\n\nTime series Analysis\n\nShipment By Product Type\n\n\nShow the code\ngrp2 <- MC2_edges_clean_mapped %>%\n  group_by(year, month, fishtype) %>%\n  summarise(no_shnpment = n()) %>%\n  filter(fishtype!=\"not fish\") %>%\n  ungroup()\n\n# using ggplot2 for creating the plot with facet_wrap\np <- ggplot(grp2, aes(x = month, y = no_shnpment, color = fishtype)) +\n  geom_line(aes(group = fishtype), line = list(shape = \"spline\", smoothing = 0.2)) +\n  geom_point() +\n  labs(title = \"Total shipment per month by fish type, 2028 - 2034\", \n       x = \"Month\", \n       y = \"Num of Shnp\") +\n  facet_wrap(~year, nrow = 1) + \n  theme(legend.position = \"bottom\") +\n  scale_x_continuous(breaks = 1:12, labels = 1:12)  # Set x-axis breaks and labels\n\n# converting ggplot2 object to plotly object\nfig2 <- ggplotly(p)\n\n# print the plot\nfig2\n\n\n\n\n\n\nUtilizing data specific to fish and seafood-related shipments, we created a time series plot to study the temporal trends. We can observe the number of shipments reached a significant peak in the year 2033. This spike was particularly seen in the months of July, August, and September for the top four fish products: ‘fish meat’, ‘crustaceans’, ‘frozen fish’, and ‘molluscs’.\nThis observation could be leveraged in our subsequent network graph analysis. By reducing the node count to concentrate on shipments pertaining to these top four fish products during these specific months in 2033, we could streamline our analysis.\n\n\n\nPrepare for Edges\n\n\nShow the code\nMC2_edges_aggregated <- MC2_edges_clean_mapped %>%\n  filter(year %in% c(2033)) %>%\n  filter(month %in% c(7, 8, 9)) %>%\n  filter(fishtype != \"not fish\") %>%\n  group_by(source, target, fishtype) %>%\n  summarise(Weight = n()) %>%\n  filter(source != target) %>%\n  filter(Weight > 20) %>%\n  ungroup()\n\n\n\n\nPrepare for Nodes\n\n\nShow the code\n# Filter rows in nodes based on matching ids in edges target and source\n\nid1 <- MC2_edges_aggregated %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- MC2_edges_aggregated %>%\n  select(target) %>%\n  rename(id = target)\n\nMC2_nodes_extracted <- rbind(id1, id2)  %>%\n  distinct()\n\n\nMC2_nodes_extracted <- MC2_nodes_extracted %>%\n  left_join(MC2_edges_aggregated %>% select(target, fishtype), by = c(\"id\" = \"target\")) %>%\n  select(id, fishtype)\n\n# Let's add a column with the group of each name. It will be useful later to color points\nMC2_nodes_extracted$group <- MC2_nodes_extracted$fishtype\n\n\n\n\nCreating the Graph Dataframe\n\n\nShow the code\nMC2_graph <- tbl_graph(nodes = MC2_nodes_extracted,\n                        edges = MC2_edges_aggregated, \n                        directed = TRUE) \n\n\nMC2_graph  \n\n\n# A tbl_graph: 274 nodes and 164 edges\n#\n# A directed acyclic simple graph with 134 components\n#\n# A tibble: 274 × 3\n  id                                              fishtype group\n  <chr>                                           <chr>    <chr>\n1 2 Wharf S.A. de C.V. Delivery                   <NA>     <NA> \n2 Adriatic Catch Ltd. Liability Co Transportation <NA>     <NA> \n3 Adriatic Tuna AS Solutions                      <NA>     <NA> \n4 Agua Limited Liability Company Services         <NA>     <NA> \n5 Andhra Pradesh   Sextant Oyj Forwading          <NA>     <NA> \n6 Angeline Sea NV Worldwide                       <NA>     <NA> \n# ℹ 268 more rows\n#\n# A tibble: 164 × 4\n   from    to fishtype    Weight\n  <int> <int> <chr>        <int>\n1     1   112 fish meat       27\n2     2   115 crustaceans     24\n3     3   122 crustaceans     36\n# ℹ 161 more rows\n\n\n\n\nShow the code\nset_graph_style()\n\ng <- ggraph(MC2_graph, \n            layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = group), \n                  size = 2)\n  \ng + facet_nodes(~group)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nPlot Network Graph\n\nPlotting of Network using Eigenvector Centrality\nDegree centrality only takes into account the number of edges for each node, but it leaves out information about ego’s alters.\nHowever, we might think that power comes from being tied to powerful people. If A and B have the same degree centrality, but A is tied to all high degree people and B is tied to all low degree people, then intuitively we want to see A with a higher score than B.\nEigenvector centrality takes into account alters’ power. In our Network graph, Eigenvector score for each node will be calculated using igraph package.\nDue to the large number of edges within the interaction, we will focus only the top 20% nodes based on their eigenvector centrality score.\n\n\n\n\n\n\nNote\n\n\n\nNote: This part of codes cites from Senior Mr Jordan Ong’s Take-Home_Exercise 6 in 2021-2022 April Term).\n\n\n\nEigen centralityNodes AttributesStatistical Plot\n\n\n\n\nShow the code\nquantile_graph <- quantile(eigen_centrality(MC2_graph)$vector,\n         probs = seq(0, 1, 1/5)\n         )\nV(MC2_graph)$size = eigen_centrality(MC2_graph)$vector\n\nMC2_graph_aggregated <- delete_vertices(MC2_graph, V(MC2_graph)[size < quantile_graph[5]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(MC2_graph_aggregated)\n\nquantile_graph_aggregated <- quantile(V(MC2_graph_aggregated)$size, #identify top 20% of the new vertices\n         probs = seq(0, 1, 1/5)\n         )\n\n\nV(MC2_graph_aggregated)$color <- ifelse (V(MC2_graph_aggregated)$size > quantile_graph_aggregated[5], \"darkgoldenrod3\", \"azure3\") #color yellow if vertices is top 20%\nE(MC2_graph_aggregated)$color <- \"grey\"\nV(MC2_graph_aggregated)$size <- V(MC2_graph_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(MC2_graph_aggregated)$id <- ifelse (V(MC2_graph_aggregated)$size*0.065 > quantile_graph_aggregated[5],V(MC2_graph_aggregated)$id,NA)\n#label the vertices if vertices belongs to the top 20%\n\n\nplot(MC2_graph_aggregated, edge.arrow.size = 0.25, edge.arrow.mode = \"-\", \n     vertex.label = V(MC2_graph_aggregated)$id, vertex.label.cex = 0.65, \n     vertex.label.font = 1, main = \"Which companies are having  to other nodes?\")\n\n\n\n\n\nA higher number of links could potentially indicate a higher level of activity, collaborations, or partnerships, which might increase the likelihood of a company undergoing name changes.\n\n\n\n\nShow the code\nvertex_attr(MC2_graph_aggregated, index = V(MC2_graph_aggregated)$size*0.065 > quantile_graph_aggregated[5]) \n\n\n$id\n [1] \"Balkan Cat ОАО Transport\"            \n [2] \"Blue Horizon Family &\"               \n [3] \"Sea Breezes S.A. de C.V. Freight \"   \n [4] \"Yenisei  Eel GmbH & Co. KG Services\" \n [5] \"Caracola del Sol Services\"           \n [6] \"Costa de la Felicidad Shipping\"      \n [7] \"Orange River   Incorporated Shipping\"\n [8] \"Selous Game Reserve  S.A. de C.V.\"   \n [9] \"hǎi dǎn Corporation Wharf\"           \n[10] \"Mar del Este CJSC\"                   \n[11] \"Pao gan SE Seal\"                     \n\n$fishtype\n [1] NA            NA            NA            NA            \"crustaceans\"\n [6] \"crustaceans\" \"crustaceans\" \"crustaceans\" \"crustaceans\" \"crustaceans\"\n[11] \"crustaceans\"\n\n$group\n [1] NA            NA            NA            NA            \"crustaceans\"\n [6] \"crustaceans\" \"crustaceans\" \"crustaceans\" \"crustaceans\" \"crustaceans\"\n[11] \"crustaceans\"\n\n$size\n [1]  5.481011  8.338480 13.154593  5.523848 10.253177  7.721414  5.481894\n [8]  6.076499  5.462136 15.384615  7.830756\n\n$color\n [1] \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\"\n [5] \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\"\n [9] \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\"\n\n\nThrough the nodes attributes of the top 20% of Eigenvector Centrality Score, we see that majority of nodes are having the same product type which is crustaceans. We will now analyse to see if the product type affect the Eigen betweenness score. A non-parametric test is conducted to provided statistical evidence whether to reject or accept the null hypothesis.\n\n\nHypothesis testing: Does types of fishing affect eigen betweenness score?\n\n\nShow the code\nMC2_edges_aggregated_r <- MC2_edges_clean_mapped %>%\n  #filter(year %in% c(2028)) %>%\n  filter(fishtype !=\"not fish\") %>%\n  group_by(source, target, fishtype) %>%\n  summarise(Weight = n()) %>%\n  filter(source != target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n# Filter rows in nodes based on matching ids in edges target and source\n\nid3 <- MC2_edges_aggregated_r %>%\n  select(source) %>%\n  rename(id = source)\nid4 <- MC2_edges_aggregated_r %>%\n  select(target) %>%\n  rename(id = target)\n\nMC2_nodes_extracted_r <- rbind(id3, id4)  %>%\n  distinct()\n\n\nMC2_nodes_extracted_r <- MC2_nodes_extracted_r %>%\n  left_join(MC2_edges_aggregated_r %>% select(target, fishtype), by = c(\"id\" = \"target\")) %>%\n  select(id, fishtype)\n\n\nMC2_graph_r <- tbl_graph(nodes = MC2_nodes_extracted_r,\n                        edges = MC2_edges_aggregated_r, \n                        directed = TRUE) \n\nMC2_graph_r \n\n\n# A tbl_graph: 33753 nodes and 30273 edges\n#\n# A directed multigraph with 26526 components\n#\n# A tibble: 33,753 × 2\n  id                                   fishtype\n  <chr>                                <chr>   \n1 \" Direct Herring Company Transit\"    <NA>    \n2 \" Direct LLC Marine biology\"         <NA>    \n3 \" Direct Shark Oyj Marine sanctuary\" <NA>    \n4 \"-1515\"                              molluscs\n5 \"-1515\"                              molluscs\n6 \"-28\"                                <NA>    \n# ℹ 33,747 more rows\n#\n# A tibble: 30,273 × 4\n   from    to fishtype    Weight\n  <int> <int> <chr>        <int>\n1     1 16469 molluscs         5\n2     1 16470 molluscs         6\n3     1  2703 crustaceans      6\n# ℹ 30,270 more rows\n\n\nShow the code\nV(MC2_graph_r)$size = eigen_centrality(MC2_graph_r)$vector\n\n\nMC2_graph_analysis_r <- as.data.frame(MC2_graph_r)\n\np1 <- ggbetweenstats(\n  data = MC2_graph_analysis_r,\n  x = fishtype,\n  y = size,\n  xlab = \"fishtype\",\n  ylab = \"EV Centrality \\nScore\",\n  title = \"Will betweenness score be affected by fishing type?\",\n  type = \"np\", #conduct non-parametric test\n  conf.level = 0.95,\n  mean.ci = TRUE,\n  package = \"ggsci\",\n  palette = \"default_jco\"\n) +\n  ggplot2::theme(\n    axis.title.y = element_text(angle = 0, size = 9),\n    axis.title.x = element_text(size = 9),\n    plot.title = element_text(color = \"dimgrey\", size = 12, hjust = 0.5)\n)\n\np1\n\n\n\n\n\n\n\n\nFrom the statistical plot we have P-values is less than 0.05, it indicates that there is a statistically significant difference in the eigen betweenness scores across different fishing types.\nTherefore, we can conclude that the fishing type has a significant effect on the eigen betweenness scores in the network. This finding implies that the type of fishing has an influence on the structural importance or centrality of the nodes in the network, as measured by eigen betweenness.\n\n\n\nVisNetwork Graph\n\nCommunity Detection\n\ncluster_edge_betweennessCluster louvain\n\n\nThe community detection is performed using the cluster_edge_betweenness function from the igraph package. This function calculates the edge betweenness centrality for each edge in the graph and then uses it to detect communities.\n\n\nShow the code\nedges_df1 <- MC2_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC2_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# Perform community detection using the cluster edge betweenness\ncommunities <- cluster_edge_betweenness(MC2_graph)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE,\n                         type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\ncluster_edge_betweenness\n\nthe large number of nodes forming a single largest community suggests that the graph has strong connections and relatively low edge betweenness centrality across its edges.\nThis indicates a cohesive and densely connected network where most nodes are closely linked, resulting in a single dominant community.\n\n\n\ncluster_louvain is a community detection algorithm implemented in the igraph package in R. It is based on the Louvain method, which is a popular and efficient algorithm for detecting communities in networks. The Louvain method aims to optimize a quality function known as modularity, which measures the strength of division of a network into communities.\n\n\nShow the code\nedges_df2 <- MC2_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df2 <- MC2_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# Convert the graph to undirected\nMC2_graph_undirected <- as.undirected(MC2_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC2_graph_undirected)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df2$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df2, edges_df2) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\ncluster_louvain\nIn the cluster_louvain plot, it presences 8 small clusters suggests that the algorithm has identified distinct communities within the graph based on the optimization of modularity. These smaller clusters indicate subsets of nodes that are more densely connected internally and have fewer connections between them compared to the cluster_edge_betweenness result.\n\n\n\nIn our case, we would like to identify a clearer communities that potentially represent separate business cluster, cluster_louvain can be good choice. As it tends to produce well-separated communities with higher modularity score so I can capture smaller but tightly-knit communities within a larger network."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex6/Hands-on_Ex6.html",
    "href": "Hands-on_Exercies/Hands-on_Ex6/Hands-on_Ex6.html",
    "title": "Hands-on_Ex6 - 13 Creating Ternary Plot with R",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Exercies/Hands-on_Ex6/Hands-on_Ex6.html#installing-and-launching-r-packages",
    "href": "Hands-on_Exercies/Hands-on_Ex6/Hands-on_Ex6.html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex6 - 13 Creating Ternary Plot with R",
    "section": "13.2 Installing and launching R packages",
    "text": "13.2 Installing and launching R packages\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\n\nShow the code\npacman::p_load('plotly', 'tidyverse')"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_old.html",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_old.html",
    "title": "Take-home_Ex2",
    "section": "",
    "text": "Show the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, tidyverse, lubridate, igraph, ggiraph, ggplot2, ggthemes, patchwork, plotly, hrbrthemes)\n\n\n\n\nShow the code\nMC2 <- fromJSON(\"data/mc2_challenge_graph.json\")\n\n\nwhatever source and target in edges, must be appeared in nodes\n\n\nShow the code\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  select(id, shpcountry, rcvcountry)\n\n\n\nMC2_edges <- as_tibble(MC2$links) %>%\n  mutate(Arrivaldate = ymd(arrivaldate)) %>%\n  mutate(year = year(Arrivaldate)) %>%\n  mutate(month = month(Arrivaldate)) %>%\n  select(source, target, Arrivaldate, year, month, hscode, valueofgoods_omu, volumeteu, weightkg, valueofgoodsusd) %>%\n  distinct()\n\n# MC2_edges_r <- MC2_edges %>%\n#   rename(source_label = source) %>%\n#   left_join(MC2_nodes, by = c(\"source_label\" = \"label\")) %>%\n#   mutate(source = id) %>%\n#   select(-id)\n#   \n# MC2_edges_r <- MC2_edges_r %>%\n#   rename(target_label = target) %>%\n#   left_join(MC2_nodes, by = c(\"target_label\" = \"label\")) %>%\n#   mutate(target = id) %>%\n#   select(-id, -shpcountry.x, -shpcountry.y, -rcvcountry.x, -rcvcountry.y)\n\n\n\n\nShow the code\n#Check for missing values\nany(is.na(MC2_nodes))\n\n\n[1] TRUE\n\n\nShow the code\nany(is.na(MC2_edges))\n\n\n[1] TRUE\n\n\n\n\nShow the code\n# Calculate the percentage of NA values in each column\nnodes_na_pct <- colMeans(is.na(MC2_nodes)) * 100\n\n# Print the NA percentages\nprint(nodes_na_pct)\n\n\n        id shpcountry rcvcountry \n   0.00000   64.66624    8.41335 \n\n\nShow the code\n# Calculate the percentage of NA values in each column\nedges_na_pct <- colMeans(is.na(MC2_edges)) * 100\n\n# Print the NA percentages\nprint(edges_na_pct)\n\n\n          source           target      Arrivaldate             year \n         0.00000          0.00000          0.00000          0.00000 \n           month           hscode valueofgoods_omu        volumeteu \n         0.00000          0.00000         99.99471          9.38167 \n        weightkg  valueofgoodsusd \n         0.00000         54.36443 \n\n\nThe valueofgoods_omu has 99% of na values, therefore we can remove it from the edges table\n\n\nShow the code\n#drop the valueofgoods_omu column, and remove rows with missing value in volumnteu column\nMC2_edges_clean <- MC2_edges[, -which(names(MC2_edges) == \"valueofgoods_omu\")]\nMC2_edges_clean <- MC2_edges_clean[!is.na(MC2_edges_clean$volumeteu), ]\n\nglimpse(MC2_edges_clean)\n\n\nRows: 4,811,006\nColumns: 9\n$ source          <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son'…\n$ target          <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica Ma…\n$ Arrivaldate     <date> 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028-…\n$ year            <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028, …\n$ month           <dbl> 2, 3, 2, 2, 9, 10, 4, 6, 9, 9, 2, 2, 4, 4, 3, 9, 3, 3,…\n$ hscode          <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"470…\n$ volumeteu       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ weightkg        <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, 6…\n$ valueofgoodsusd <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 586…\n\n\nShow the code\nMC2_nodes_clean <- dplyr::mutate(MC2_nodes, \n                                shpcountry = ifelse(is.na(shpcountry), \"others\", shpcountry),\n                                rcvcountry = ifelse(is.na(rcvcountry), \"others\", rcvcountry))\n\nglimpse(MC2_nodes_clean)\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", \"others\", \"Oceanus\", \"others\", \"Oceanus\", \"Kon…\n$ rcvcountry <chr> \"Oceanus\", \"others\", \"Oceanus\", \"others\", \"Oceanus\", \"Utopo…\n\n\n\nLoad all Bundle files, distinct hscode, create a column fishtype\n\n\nShow the code\n# carp <- fromJSON(\"data/bundles/carp.json\")\n# carp_hscode <- as_tibble(carp$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'carp')\n\n\n\n\nShow the code\n# catfish <- fromJSON(\"data/bundles/catfish.json\")\n# \n# catfish_hscode <- as_tibble(catfish$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'catfish')\n\n\n\n\nShow the code\n# chub_mackerel <- fromJSON(\"data/bundles/chub_mackerel.json\")\n# \n# chub_mackerel_hscode <- as_tibble(chub_mackerel$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'chub_mackerel')\n\n\n\n\nShow the code\n# cod2 <- fromJSON(\"data/bundles/cod2.json\")\n# \n# cod2_hscode <- as_tibble(cod2$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'cod2')\n\n\n\n\nShow the code\n# herring <- fromJSON(\"data/bundles/herring.json\")\n# \n# herring_hscode <- as_tibble(herring$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'herring')\n\n\n\n\nShow the code\n# lichen <- fromJSON(\"data/bundles/lichen.json\")\n# \n# lichen_hscode <- as_tibble(lichen$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'lichen')\n\n\n\n\nShow the code\n# mackerel <- fromJSON(\"data/bundles/mackerel.json\")\n# \n# mackerel_hscode <- as_tibble(mackerel$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'mackerel')\n\n\n\n\nShow the code\n# pollock <- fromJSON(\"data/bundles/pollock.json\")\n# \n# pollock_hscode <- as_tibble(pollock$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = 'pollock')\n\n\n\n\nShow the code\n# salmon <- fromJSON(\"data/bundles/salmon.json\")\n# \n# salmon_hscode <- as_tibble(salmon$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = \"`salmon`\")\n\n\n\n\nShow the code\n# salmon_wgl <- fromJSON(\"data/bundles/salmon_wgl.json\")\n# \n# salmon_wgl_hscode <- as_tibble(salmon_wgl$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = \"salmon_wgl\")\n\n\n\n\nShow the code\n# shark <- fromJSON(\"data/bundles/shark.json\")\n# \n# shark_hscode <- as_tibble(shark$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = \"shark\")\n\n\n\n\nShow the code\n# tuna <- fromJSON(\"data/bundles/tuna.json\")\n# \n# tuna_hscode <- as_tibble(tuna$links) %>%\n#   select(hscode) %>%\n#   distinct() %>%\n#   mutate(fishtype = \"tuna\")\n\n\n\n\nShow the code\n# bundle_hscode <- rbind(carp_hscode, catfish_hscode, chub_mackerel_hscode, cod2_hscode, herring_hscode, lichen_hscode, mackerel_hscode, pollock_hscode, salmon_hscode, salmon_wgl_hscode,\n#                        shark_hscode, tuna_hscode)  %>%\n#   distinct()\n\n\n\n\nMerge bundle file to main graph edges table by hscode\n\n\nShow the code\n# # Merge MC2_edges_clean with carp_hscode\n# MC2_edges_clean_merged <- merge(MC2_edges_clean, bundle_hscode, by = \"hscode\", all.x = TRUE)\n# \n# \n# MC2_edges_clean_merged <- dplyr::mutate(MC2_edges_clean_merged, \n#                                 fishtype = ifelse(is.na(fishtype), \"unknown\", fishtype))\n\n\n\n\nShow the code\nMC2_edges_clean_mapped <- MC2_edges_clean %>%\n  mutate(fishtype = case_when(\n    startsWith(hscode, \"301\") ~ \"live fish\",\n    startsWith(hscode, \"302\") ~ \"fresh fish\",\n    startsWith(hscode, \"303\") ~ \"frozen fish\",\n    startsWith(hscode, \"304\") ~ \"fish meat\",\n    startsWith(hscode, \"305\") ~ \"processed fish\",\n    startsWith(hscode, \"306\") ~ \"crustaceans\",  #like lobster or shrimps\n    startsWith(hscode, \"307\") ~ \"molluscs\",  #like Oysters or Abalone\n    startsWith(hscode, \"308\") ~ \"aquatic invertebrates\", #like Sea cucumbers\n    TRUE ~ \"not fish\"\n  ))\n\n# MC2_edges_clean_filtered <- MC2_edges_clean_mapped %>%\n#   filter(!is.na(fishtype))\n\n\n\n\nShow the code\ngrp1 <- MC2_edges_clean_mapped %>%\n  group_by(year, month, fishtype) %>%\n  summarise(no_shnpment = n()) %>%\n  filter(fishtype !=\"not fish\") %>%\n  ungroup()\n#  filter(year %in% c(2032, 2033)) %>%\n#  top_n(round(0.2 * n()), wt = avg_weightkg)\n\ntt <- c(paste(\"Year:\", grp1$year, \"<br>Month:\", grp1$month, \"<br>fishtype:\", grp1$fishtype, \"<br>NoShipment:\", grp1$no_shnpment))\n\nfig1 <- grp1 %>%\n  mutate(month = factor(month, levels = 1:12, labels = 1:12)) %>%\n  ggplot(aes(x = month, y = no_shnpment, fill = fishtype, text = tt)) +\n  geom_bar(position = \"stack\", stat = \"identity\") +\n  scale_fill_viridis(discrete = TRUE) +\n  labs(title = \"No of shipment per month, 2028 - 2034\", x = 'Month', y = 'No of shipment') +\n  facet_wrap(~year, nrow=1) +\n  theme_ipsum() +\n  theme(legend.position = \"none\") +\n  xlab(\"\") +\n  scale_x_discrete(labels = 1:12)\n\nfig1 <- ggplotly(fig1, tooltip = \"text\")\n\nfig1\n\n\n\n\n\n\n\n\nDistribution plot\n\n\nShow the code\nshipcountry <- MC2_nodes_clean %>%\n  plot_ly(x = ~shpcountry) %>%\n  add_histogram(color = I('#808de8')) %>%\n  layout(title = \"Distribution of Countries that Company Associated with when Shipping\",\n         yaxis = list(title = \"No. of Companies Associated\"),\n         xaxis = list(title = \"Country\"),\n         subtitle = \"Vast Challenge 2023\",\n         barmode = \"overlay\",\n         bargap = 0.1)\n\nrevcountry <- MC2_nodes_clean %>%\n  plot_ly(x = ~rcvcountry) %>%\n  add_histogram(color = I('#6eba6a')) %>%\n  layout(title = \"Distribution of Countries that Company Associated with when shipping & Receiving\",\n         yaxis = list(title = \"No. of Companies Associated\"),\n         xaxis = list(title = \"Country\"),\n         subtitle = \"Vast Challenge 2023\",\n         barmode = \"overlay\",\n         bargap = 0.1)\n\nsubplot(shipcountry, revcountry, nrows = 1, titleX = FALSE) %>%\n  layout(plot.title = list(size = 14, font = list(face = \"bold\")))\n\n\n\n\n\n\n\n\nShow the code\nglimpse(MC2_edges_clean_mapped)\n\n\nRows: 4,811,006\nColumns: 10\n$ source          <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son'…\n$ target          <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica Ma…\n$ Arrivaldate     <date> 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028-…\n$ year            <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028, …\n$ month           <dbl> 2, 3, 2, 2, 9, 10, 4, 6, 9, 9, 2, 2, 4, 4, 3, 9, 3, 3,…\n$ hscode          <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"470…\n$ volumeteu       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ weightkg        <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, 6…\n$ valueofgoodsusd <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 586…\n$ fishtype        <chr> \"not fish\", \"not fish\", \"not fish\", \"not fish\", \"not f…\n\n\n\n\nNum shipment by fish type per year\n\n\nShow the code\ngrp2 <- MC2_edges_clean_mapped %>%\n  group_by(year, month, fishtype) %>%\n  summarise(no_shnpment = n()) %>%\n  filter(fishtype!=\"not fish\") %>%\n  ungroup()\n\ntt <- c(paste(\"Year:\", grp2$year, \"<br>Num of shnp:\", grp2$no_shnpment, \"<br>fishtype:\", grp2$fishtype))\n\nfig2 <- grp2 %>%\n  ggplot(aes(x = month, y = no_shnpment, colour = fishtype)) +\n  geom_smooth(aes(group = fishtype), alpha = 0.1, se = FALSE) +\n  geom_point_interactive(aes(tooltip = tt), size = 4) +\n  theme_excel_new() +\n  scale_x_continuous(breaks = seq(1, 12, by = 1), limits = c(1, 12)) +\n  scale_y_continuous(breaks = seq(0, 6500, by = 1000), limits = c(0, 6500)) +\n  labs(title = \"Total shipment per month by fish type, 2028 - 2034\", x = 'Month', y = 'Num of Shnp') +\n  facet_wrap(~year, nrow = 1) +\n  guides(color = FALSE)\n\ngirafe(ggobj = fig2, width_svg = 12)\n\n\n\n\n\n\n\n\nShow the code\n# grp2 <- MC2_edges_clean_mapped %>%\n#   group_by(year, month, fishtype) %>%\n#   summarise(no_shnpment = n()) %>%\n#   filter(fishtype!=\"not fish\") %>%\n#   ungroup()\n# \n# tt1 <- c(paste(\"Year:\", grp2$year, \"<br>Num of shnp:\", grp2$no_shnpment, \"<br>fishtype:\", grp2$fishtype))\n# \n# fig2 <- grp2 %>%\n#   plot_ly(x = ~month, y = ~no_shnpment, color = ~fishtype, colors = \"viridis\",\n#           type = \"scatter\", mode = \"markers\", hovertext = ~tt1) %>%\n#   add_lines(x = ~month, y = ~no_shnpment, color = ~fishtype, colors = \"viridis\",\n#             line = list(shape = \"spline\", smoothing = 0.2)) %>%\n#   layout(title = \"Total shipment per month by fish type, 2028 - 2034\",\n#          xaxis = list(title = \"Year\"),\n#          yaxis = list(title = \"Num of Shnp\"),\n#          legend = list(orientation = \"h\")) %>%\n#   subplot(nrows = 1, shareX = TRUE) \n# \n# fig2\n\n\ngrp2 <- MC2_edges_clean_mapped %>%\n  group_by(year, month, fishtype) %>%\n  summarise(no_shnpment = n()) %>%\n  filter(fishtype!=\"not fish\") %>%\n  ungroup()\n\n# using ggplot2 for creating the plot with facet_wrap\np <- ggplot(grp2, aes(x = month, y = no_shnpment, color = fishtype)) +\n  geom_line(aes(group = fishtype), line = list(shape = \"spline\", smoothing = 0.2)) +\n  geom_point() +\n  labs(title = \"Total shipment per month by fish type, 2028 - 2034\", \n       x = \"Month\", \n       y = \"Num of Shnp\") +\n  facet_wrap(~year, nrow = 1) + \n  theme(legend.position = \"bottom\")\n\n# converting ggplot2 object to plotly object\nfig2 <- ggplotly(p)\n\n# print the plot\nfig2\n\n\n\n\n\n\n\n\nShow the code\nMC2_edges_aggregated <- MC2_edges_clean_mapped %>%\n  # filter(year %in% c(2032)) %>%\n  filter(fishtype %in% c(\"frozen fish\", \"fresh fish\")) %>%\n  group_by(source, target, fishtype, year) %>%\n  summarise(Weight = n()) %>%\n  filter(source != target) %>%\n  filter(Weight > 20) %>%\n  ungroup()\n\n\n\n\nShow the code\n# Filter rows in nodes based on matching ids in edges target and source\n\nid1 <- MC2_edges_aggregated %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- MC2_edges_aggregated %>%\n  select(target) %>%\n  rename(id = target)\n\nMC2_nodes_extracted <- rbind(id1, id2)  %>%\n  distinct()\n\n# # Let's add a column with the group of each name. It will be useful later to color points\n# MC2_nodes_extracted$group  <-  MC2_edges_aggregated$source[match(MC2_nodes_extracted$id, MC2_edges_aggregated$target)]\n\nMC2_nodes_extracted <- MC2_nodes_extracted %>%\n  left_join(MC2_edges_aggregated %>% select(target, fishtype), by = c(\"id\" = \"target\")) %>%\n  select(id, fishtype)\n\n# Let's add a column with the group of each name. It will be useful later to color points\nMC2_nodes_extracted$group <- MC2_nodes_extracted$fishtype\n\n\n\n\nShow the code\nMC2_graph <- tbl_graph(nodes = MC2_nodes_extracted,\n                        edges = MC2_edges_aggregated, \n                        directed = TRUE) \n\n\nMC2_graph  \n\n\n# A tbl_graph: 502 nodes and 366 edges\n#\n# A directed acyclic multigraph with 303 components\n#\n# A tibble: 502 × 3\n  id                                     fishtype group\n  <chr>                                  <chr>    <chr>\n1 1 Limited Liability Company            <NA>     <NA> \n2 2 Limited Liability Company            <NA>     <NA> \n3 Andhra Pradesh   Sextant Oyj Forwading <NA>     <NA> \n4 Angeline Sea NV Worldwide              <NA>     <NA> \n5 Aqua Aura SE Marine life               <NA>     <NA> \n6 Aqua Mermaid Seafarer Sp Solutions     <NA>     <NA> \n# ℹ 496 more rows\n#\n# A tibble: 366 × 5\n   from    to fishtype     year Weight\n  <int> <int> <chr>       <dbl>  <int>\n1     1   140 frozen fish  2034     28\n2     2   144 frozen fish  2033     32\n3     2   144 frozen fish  2034     30\n# ℹ 363 more rows\n\n\n\n\nShow the code\n# set.seed (1234)\n# g <- MC2_graph %>%\n#   mutate(community = as.factor(group_edge_betweenness(weights = Weight))) %>%\n#   ggraph(layout = \"fr\") + \n#   geom_edge_link(aes(width=Weight), \n#                  alpha=0.2) +\n#   scale_edge_width(range = c(0.1, 5)) +\n#   geom_node_point(aes(colour = community), show.legend = FALSE) \n# \n# g+theme_graph()\n\nset.seed(1234)\ng <- MC2_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight))) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width = Weight), alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community, shape = group), show.legend = FALSE) +\n  scale_shape_manual(values = c(\"frozen fish\" = 16))  # Assign different shapes based on fishtype\n\ng + theme_graph()\n\n\n\n\n\n\n\nShow the code\nquantile_graph <- quantile(eigen_centrality(MC2_graph)$vector,\n         probs = seq(0, 1, 1/10)\n         )\nV(MC2_graph)$size = eigen_centrality(MC2_graph)$vector\n\nMC2_graph_aggregated <- delete_vertices(MC2_graph, V(MC2_graph)[size < quantile_graph[10]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(MC2_graph_aggregated)\n\nquantile_graph_aggregated <- quantile(V(MC2_graph_aggregated)$size, #identify top 10% of the new vertices\n         probs = seq(0, 1, 1/10)\n         )\n\n\nV(MC2_graph_aggregated)$color <- ifelse (V(MC2_graph_aggregated)$size > quantile_graph_aggregated[10], \"darkgoldenrod3\", \"azure3\") #color yellow if vertices is top 10%\nE(MC2_graph_aggregated)$color <- \"grey\"\nV(MC2_graph_aggregated)$size <- V(MC2_graph_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(MC2_graph_aggregated)$id <- ifelse (V(MC2_graph_aggregated)$size*0.065 > quantile_graph_aggregated[10],V(MC2_graph_aggregated)$id,NA)\n#label the vertices if vertices belongs to the top 10%\n\n\nplot(MC2_graph_aggregated, edge.arrow.size = 0.25, edge.arrow.mode = \"-\", \n     vertex.label = V(MC2_graph_aggregated)$id, vertex.label.cex = 0.65, \n     vertex.label.font = 1, main = \"Which company has most links to other nodes?\")\n\n\n\n\n\nHowever, a higher number of links could potentially indicate a higher level of activity, collaborations, or partnerships, which might increase the likelihood of a company undergoing name changes.\n\n\nShow the code\nset.seed (1234)\nGNC <- cluster_edge_betweenness(MC2_graph_aggregated, weights = NULL)\nV(MC2_graph_aggregated)$color <-membership(GNC)              #Plot setting specifying the coloring of vertices by community\nMC2_graph_aggregated$palette <- diverging_pal(length(GNC)) \nplot(MC2_graph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = \"-\", vertex.label = V(MC2_graph_aggregated)$id, vertex.label.cex = 0.65, vertex.label.font = 1, main = \"How many clusters within the same type of fishing?\")\n\n\n\n\n\n\n\nShow the code\nV(MC2_graph)$degree <- degree(MC2_graph, mode = \"in\")\nggraph(MC2_graph, layout = 'linear', circular = TRUE) +\n  geom_edge_arc(aes(colour = factor(year))) +\n  geom_node_point(aes(alpha = degree, color = MC2_nodes_extracted$group), show.legend = FALSE) +\n  coord_fixed() +\n    theme(legend.key.size = unit(2, \"lines\"),\n        legend.position = \"right\",\n        legend.box = \"vertical\")\n\n\n\n\n\n\n\nShow the code\nV(MC2_graph)$degree <- degree(MC2_graph, mode = \"in\")\n\nMC2_nodes_extracted$betweenness_centrality <- betweenness(MC2_graph)\n\nggraph(MC2_graph, layout = 'linear', circular = TRUE) +\n  geom_edge_arc(aes(colour = factor(year))) +\n  geom_node_point(aes(alpha = degree, size = MC2_nodes_extracted$betweenness_centrality, color = MC2_nodes_extracted$group), show.legend = FALSE) +\n  geom_node_text(aes(label = id), vjust = -0.5, size = 1) +\n  coord_fixed() +\n  theme(legend.key.size = unit(2, \"lines\"),\n        legend.position = \"right\",\n        legend.box = \"vertical\")\n\n\n\n\n\n\n\nShow the code\nwrite_rds(MC2_nodes_extracted, \"data/MC2_nodes_extracted.rds\")\nwrite_rds(MC2_edges_aggregated, \"data/MC2_edges_aggregated.rds\")\nwrite_rds(MC2_graph, \"data/MC2_graph.rds\")\n\n\n\n\nShow the code\n# write_csv(MC2_nodes_extracted, \"data/MC2_nodes_extracted.csv\")\n# write_csv(MC2_edges_aggregated, \"data/MC2_edges_aggregated.csv\")\n\n\n\n\nShow the code\nedges_df <- MC2_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df <- MC2_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# Let's add a column with the group of each name. It will be useful later to color points\nnodes_df$group <- edges_df$from[match(nodes_df$id, edges_df$to)]\n\n# MC2_edges_aggregated_1 <- MC2_edges_clean_merged %>%\n#   left_join(MC2_nodes_clean, by = c(\"source_label\" = \"label\")) %>%\n#   rename(from = source) %>%\n#   left_join(MC2_nodes_clean, by = c(\"target_label\" = \"label\")) %>%\n#   rename(to = target) %>%\n#   filter(year %in% c(2023)) %>%\n#   filter(fishtype == \"mackerel\") %>%\n#   group_by(from, to, fishtype, year) %>%\n#     summarise(weight = n()) %>%\n#   filter(from!=to) %>%\n#   filter(weight>20) %>%\n#   ungroup()\n#   \n# \n# MC2_nodes_clean <- MC2_nodes_clean %>%\n#   rename(group = shpcountry)\n\n\n\n\nShow the code\nvisNetwork(nodes_df,\n           edges_df) %>%\n  visIgraphLayout(layout = \"layout_with_fr\",\n                  smooth = FALSE,\n                  physics = FALSE) %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE,\n                         type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nShow the code\n# visNetwork(MC2_nodes_clean,\n#            MC2_edges_aggregated) %>%\n#   visIgraphLayout(layout = \"layout_with_fr\",\n#                   smooth = FALSE,\n#                   physics = FALSE) %>%\n#   visEdges(arrows = \"to\",\n#            smooth = list(enabled = TRUE,\n#                          type = \"curvedCW\"), \n#            color = list(highlight = \"lightgray\")) %>%\n#   visNodes(label = MC2_nodes_clean$id) %>%\n#   visOptions(selectedBy = \"group\",\n#              highlightNearest = list(enabled = TRUE,\n#                                      degree = 1,\n#                                      hover = TRUE,\n#                                      labelOnly = TRUE),\n#              nodesIdSelection = TRUE) %>%\n#   visLayout(randomSeed = 123)\n\n\n\n\nShow the code\nedges_df1 <- MC2_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC2_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# Perform community detection using the group edge betweenness algorithm\ncommunities <- cluster_edge_betweenness(MC2_graph)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE,\n                         type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nShow the code\n# Let's add a column with the group of each name. It will be useful later to color points\n# MC2_nodes_extracted$group <- MC2_edges_aggregated$source[match(MC2_nodes_extracted$id, MC2_edges_aggregated$target)]\n\nMC2_graph_2 <- tbl_graph(nodes = MC2_nodes_extracted,\n                        edges = MC2_edges_aggregated, \n                        directed = TRUE) \n\n\n\ng <- MC2_graph_2 %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width = Weight), alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(color = community, size = betweenness_centrality), show.legend = FALSE) +\n  geom_node_text(aes(label = ifelse(betweenness_centrality > quantile(betweenness_centrality, 0.9), id, \"\")), \n                 repel = TRUE, size = 3, max.overlaps = 30)\n\ng + theme_graph()"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html",
    "title": "Take-home_Ex2",
    "section": "",
    "text": "With reference to Mini-Challenge 2 of VAST Challenge 2023 and by using appropriate static and interactive statistical graphics methods, I will be revealing the:\n\nUse visual analytics to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns if any.\n\n\n\n\nTo analyse the temporal patterns, timeline visualization and network visualization will be using to identify the patterns and explore the possible the business relationship between entities.\nVisualizing Temporal Patterns:\nTimeline Visualization: Create a timeline visualization that shows the activities of companies over time. Each company can be represented as a separate entity on the timeline, and their fishing activities (both legal and illegal) can be displayed as events or bars. This allows analysts to compare the temporal patterns of different companies and identify any suspicious behavior or recurring patterns.\nTemporal Network Visualization: Represent the relationships between companies and their fishing activities as a network, where nodes represent companies and edges indicate their fishing activities. By incorporating temporal information into the visualization, such as color-coding or varying the thickness of edges based on the time of occurrence or numbers of interactions between nodes, analysts can identify patterns of illegal fishing and observe if companies reappear under different names."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#install-and-load-the-packages",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#install-and-load-the-packages",
    "title": "Take-home_Ex2",
    "section": "Install and load the packages",
    "text": "Install and load the packages\nThe following code chunks will install and load the required packages.\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, tidyverse, lubridate, igraph, ggiraph, ggplot2, ggthemes, patchwork, plotly, ggstatsplot, hrbrthemes)"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#load-the-dataset-in-json-format",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#load-the-dataset-in-json-format",
    "title": "Take-home_Ex2",
    "section": "Load the dataset in JSON format",
    "text": "Load the dataset in JSON format\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc2_challenge_graph.json into R environment.\n\n\nShow the code\nMC2 <- fromJSON(\"data/mc2_challenge_graph.json\")"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#data-wrangling",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#data-wrangling",
    "title": "Take-home_Ex2",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nExtracting the nodes and links\nThe code chunk is used to extract nodes/edges data tables from MC2 list object and save the output in a tibble data frame object called MC2_nodes and MC2_edges.\n\n\nShow the code\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  select(id, shpcountry, rcvcountry)\n\n\n\nMC2_edges <- as_tibble(MC2$links) %>%\n  mutate(Arrivaldate = ymd(arrivaldate)) %>%\n  mutate(year = year(Arrivaldate)) %>%\n  mutate(month = month(Arrivaldate)) %>%\n  select(source, target, Arrivaldate, year, month, hscode, valueofgoods_omu, volumeteu, weightkg, valueofgoodsusd) %>%\n  distinct()\n\n\n\nmutate() is used two times to create two derive fields.\nymd() of lubridate package is used to covert arrivaldate field from character data type into date data type.\nyear() of lubridate package is used to convert the values in ArrivalDate field into year values.\nmonth() of lubridate package is used to convert the values in ArrivalDate field into month values.\nselect() is used not only to select the field needed but also to re-organise the sequent of the fields.\n\n\n\nCheck for missing values\n\n\nShow the code\n#Check for missing values\nany(is.na(MC2_nodes))\n\n\n[1] TRUE\n\n\nShow the code\nany(is.na(MC2_edges))\n\n\n[1] TRUE\n\n\nShow the code\n# Calculate the percentage of NA values in each column\nnodes_na_pct <- colMeans(is.na(MC2_nodes)) * 100\n\n# Print the NA percentages\nprint(nodes_na_pct)\n\n\n        id shpcountry rcvcountry \n   0.00000   64.66624    8.41335 \n\n\nShow the code\n# Calculate the percentage of NA values in each column\nedges_na_pct <- colMeans(is.na(MC2_edges)) * 100\n\n# Print the NA percentages\nprint(edges_na_pct)\n\n\n          source           target      Arrivaldate             year \n         0.00000          0.00000          0.00000          0.00000 \n           month           hscode valueofgoods_omu        volumeteu \n         0.00000          0.00000         99.99471          9.38167 \n        weightkg  valueofgoodsusd \n         0.00000         54.36443 \n\n\nThe valueofgoods_omu has 99% of na values, therefore we can remove this variable from the edges table. In the nodes table, we have 64.6% and 8.4$ na values in shipping country and receiving country columns, we can replace the missing country names with “others”.\n\n\nShow the code\n#drop the valueofgoods_omu column, and remove rows with missing value in volumnteu column\nMC2_edges_clean <- MC2_edges[, -which(names(MC2_edges) == \"valueofgoods_omu\")]\n\nglimpse(MC2_edges_clean)\n\n\nRows: 5,309,087\nColumns: 9\n$ source          <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son'…\n$ target          <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica Ma…\n$ Arrivaldate     <date> 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028-…\n$ year            <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028, …\n$ month           <dbl> 2, 3, 2, 2, 9, 10, 4, 6, 9, 9, 2, 2, 4, 4, 3, 9, 3, 3,…\n$ hscode          <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"470…\n$ volumeteu       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ weightkg        <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, 6…\n$ valueofgoodsusd <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 586…\n\n\nShow the code\nMC2_nodes_clean <- dplyr::mutate(MC2_nodes, \n                                shpcountry = ifelse(is.na(shpcountry), \"others\", shpcountry),\n                                rcvcountry = ifelse(is.na(rcvcountry), \"others\", rcvcountry))\n\nglimpse(MC2_nodes_clean)\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", \"others\", \"Oceanus\", \"others\", \"Oceanus\", \"Kon…\n$ rcvcountry <chr> \"Oceanus\", \"others\", \"Oceanus\", \"others\", \"Oceanus\", \"Utopo…\n\n\n\n\nHSCODE Mapping\nFrom the VAST MC2 datanotes we know that Harmonized System code for the shipment can be joined with the hscodes table to get additional details.\nThe hscode table used in this exercise was extracted from the World Customs Organization website.\n\nThe hscode system is used by more than 200 countries, it comprises more than 5000 commodity groups, each identified by a first six digit code. Generally, the first six digits of the HS code are the same in all countries. Different countries, however, may add further digits to detail commodities in more detail without amending the first six digits. In this exercise, as we will be only interested in the fish/seafood products. In hscode system, Fish and crustaceans, molluscs and other aquatic invertebrates etc. start with 301 to 309. Therefore, we will map the hscode to each type of fish products by identify the first 3 digits.\n\n\nShow the code\nMC2_edges_clean_mapped <- MC2_edges_clean %>%\n  mutate(fishtype = case_when(\n    startsWith(hscode, \"301\") ~ \"live fish\",\n    startsWith(hscode, \"302\") ~ \"fresh fish\",\n    startsWith(hscode, \"303\") ~ \"frozen fish\",\n    startsWith(hscode, \"304\") ~ \"fish meat\",\n    startsWith(hscode, \"305\") ~ \"processed fish\",\n    startsWith(hscode, \"306\") ~ \"crustaceans\",  #like lobster or shrimps\n    startsWith(hscode, \"307\") ~ \"molluscs\",  #like Oysters or Abalone\n    startsWith(hscode, \"308\") ~ \"aquatic invertebrates\", #like Sea cucumbers?\n    startsWith(hscode, \"309\") ~ \"seafood flours\",  #fish powder, shrimp powder?\n    TRUE ~ \"not fish\"\n  ))"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#visualization",
    "href": "Take-home_Exercise/Take-home_Ex2/Take-home_Ex2r_2jun.html#visualization",
    "title": "Take-home_Ex2",
    "section": "Visualization",
    "text": "Visualization\n\nVisualising Nodes Distribution\n\n\nShow the code\nsource_nodes_g <- MC2_nodes_clean %>%\n  left_join(MC2_edges_clean_mapped %>% select(source, fishtype), by = c(\"id\" = \"source\")) %>%\n  select(id, fishtype)\n\nsource_nodes_g <- source_nodes_g %>%\n  count(fishtype) %>%\n  arrange(n) %>%\n  mutate(fishtype = factor(fishtype, levels = fishtype))\n\nsource_nodes_g <- source_nodes_g %>%\n  plot_ly(x = ~reorder(fishtype, n), y = ~n, type = \"bar\", color = I('#808de8'), \n          text = ~n, textposition = \"auto\", hoverinfo = \"text\", \n          texttemplate = \"%{y}\") %>%\n  layout(\n    title = list(text = \"Distribution of source nodes by fishtype\", x = 0.5),\n    annotations = list(\n      text = \"Vast Challenge 2023\",\n      x = 0.5, y = 1.05, xref = \"paper\", yref = \"paper\", showarrow = FALSE\n    ),\n    yaxis = list(title = \"No. of Companies\"),\n    xaxis = list(title = \"fishtype\", tickangle = -90),\n    showlegend = FALSE\n  )\n\nsource_nodes_g\n\n\n\n\n\n\nUpon evaluating the node distribution plot delineated by product type, it becomes clear that entities not related to the fish or seafood industries account for the majority of the data. Followed by ‘fish meat’, ‘crustaceans’, and ‘frozen fish’ in decreasing order.\nGiven our task is to analyze patterns among fishing companies, it would be prudent to narrow down our data set and filter out irrelevant noise. In this context, companies identified as ‘not fish’ that do not engage in fish or seafood related operations may skew the analysis and hence, should be removed.\n\n\nTimeline Visualization\n\n\nShow the code\ngrp1 <- MC2_edges_clean_mapped %>%\n  group_by(year, month, fishtype) %>%\n  summarise(no_shnpment = n()) %>%\n  filter(fishtype != \"not fish\") %>%\n  ungroup()\n\ntt <- c(paste(\"Year:\", grp1$year, \"<br>Month:\", grp1$month, \"<br>fishtype:\", grp1$fishtype, \"<br>NoShipment:\", grp1$no_shnpment))\n\nfig1 <- grp1 %>%\n  mutate(month = factor(month, levels = 1:12, labels = 1:12)) %>%\n  ggplot(aes(x = month, y = no_shnpment, fill = fishtype, text = tt)) +\n  geom_bar(position = \"stack\", stat = \"identity\") +\n  scale_fill_viridis(discrete = TRUE) +\n  labs(title = \"No of shipment per month, 2028 - 2034\", x = 'Month', y = 'No of shipment') +\n  theme(legend.position = \"none\") +\n  xlab(\"\") +\n  scale_x_discrete(labels = 1:12)\n\nfig1 <- ggplotly(fig1, tooltip = \"text\")\n\n# Create subplot layout\nsubplot <- subplot(fig1, nrows = 1, shareX = TRUE)\n\nsubplot\n\n\n\n\n\n\nWe examined above plot of the monthly shipment count, organized by fish type (excluding non-fish products), revealed distinct temporal patterns. Notably a dip in shipments was observed in April, followed by a gradually raising trend to a peak in October. This is then succeeded stable trend in November and December, suggesting a stabilization of activity during these months.\nSuch patterns could be attributed to the majority of fisheries operating in accordance with seasonal cycles, which affect the timing and intensity of their fishing activities. Consequently, our subsequent analyses will refine the focus to those months demonstrating higher fishing activities.\n\n\nNum shipment by fish type per year\n\n\nShow the code\ngrp2 <- MC2_edges_clean_mapped %>%\n  group_by(year, month, fishtype) %>%\n  summarise(no_shnpment = n()) %>%\n  filter(fishtype!=\"not fish\") %>%\n  ungroup()\n\n# using ggplot2 for creating the plot with facet_wrap\np <- ggplot(grp2, aes(x = month, y = no_shnpment, color = fishtype)) +\n  geom_line(aes(group = fishtype), line = list(shape = \"spline\", smoothing = 0.2)) +\n  geom_point() +\n  labs(title = \"Total shipment per month by fish type, 2028 - 2034\", \n       x = \"Month\", \n       y = \"Num of Shnp\") +\n  facet_wrap(~year, nrow = 1) + \n  theme(legend.position = \"bottom\") +\n  scale_x_continuous(breaks = 1:12, labels = 1:12)  # Set x-axis breaks and labels\n\n# converting ggplot2 object to plotly object\nfig2 <- ggplotly(p)\n\n# print the plot\nfig2\n\n\n\n\n\n\nUtilizing data specific to fish and seafood-related shipments, we created a time series plot to study the temporal trends. We can observed the number of shipments reached a significant peak in the year 2033. This spike was particularly seen in the months of July, August, and September for the top four fish products: ‘fish meat’, ‘crustaceans’, ‘frozen fish’, and ‘molluscs’.\nThis observation could be leveraged in our subsequent network graph analysis. By reducing the node count to concentrate on shipments pertaining to these top four fish products during these specific months in 2033, we could streamline our analysis.\n\n\nPrepare for Edges\n\n\nShow the code\nMC2_edges_aggregated <- MC2_edges_clean_mapped %>%\n  filter(year %in% c(2033)) %>%\n  filter(month %in% c(7, 8, 9)) %>%\n  filter(fishtype != \"not fish\") %>%\n  group_by(source, target, fishtype, year) %>%\n  summarise(Weight = n()) %>%\n  filter(source != target) %>%\n  filter(Weight > 20) %>%\n  ungroup()\n\n\n\n\nPrepare for Nodes\n\n\nShow the code\n# Filter rows in nodes based on matching ids in edges target and source\n\nid1 <- MC2_edges_aggregated %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- MC2_edges_aggregated %>%\n  select(target) %>%\n  rename(id = target)\n\nMC2_nodes_extracted <- rbind(id1, id2)  %>%\n  distinct()\n\n\nMC2_nodes_extracted <- MC2_nodes_extracted %>%\n  left_join(MC2_edges_aggregated %>% select(target, fishtype), by = c(\"id\" = \"target\")) %>%\n  select(id, fishtype)\n\n# Let's add a column with the group of each name. It will be useful later to color points\nMC2_nodes_extracted$group <- MC2_nodes_extracted$fishtype\n\n\n\n\nCreating the graph dataframe\n\n\nShow the code\nMC2_graph <- tbl_graph(nodes = MC2_nodes_extracted,\n                        edges = MC2_edges_aggregated, \n                        directed = TRUE) \n\n\nMC2_graph  \n\n\n# A tbl_graph: 274 nodes and 164 edges\n#\n# A directed acyclic simple graph with 134 components\n#\n# A tibble: 274 × 3\n  id                                              fishtype group\n  <chr>                                           <chr>    <chr>\n1 2 Wharf S.A. de C.V. Delivery                   <NA>     <NA> \n2 Adriatic Catch Ltd. Liability Co Transportation <NA>     <NA> \n3 Adriatic Tuna AS Solutions                      <NA>     <NA> \n4 Agua Limited Liability Company Services         <NA>     <NA> \n5 Andhra Pradesh   Sextant Oyj Forwading          <NA>     <NA> \n6 Angeline Sea NV Worldwide                       <NA>     <NA> \n# ℹ 268 more rows\n#\n# A tibble: 164 × 5\n   from    to fishtype     year Weight\n  <int> <int> <chr>       <dbl>  <int>\n1     1   112 fish meat    2033     27\n2     2   115 crustaceans  2033     24\n3     3   122 crustaceans  2033     36\n# ℹ 161 more rows\n\n\n\n\nPlot Network Graph\n\n\nShow the code\nset.seed (1234)\ng <- MC2_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight))) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community), show.legend = FALSE)\n\ng+theme_graph()\n\n\n\n\n\nShow the code\n# set.seed(1234)\n# g <- MC2_graph %>%\n#   mutate(betweenness_centrality = centrality_betweenness()) %>%\n#   mutate(community = as.factor(group_edge_betweenness(weights = Weight))) %>%\n#   ggraph(layout = \"fr\") +\n#   geom_edge_link(aes(width = Weight), alpha = 0.2) +\n#   scale_edge_width(range = c(0.1, 5)) +\n#   geom_node_point(aes(colour = community), show.legend = FALSE) +\n#   geom_node_text(aes(label = ifelse(betweenness_centrality > quantile(betweenness_centrality, 0.9), id, \"\")),\n#                  repel = TRUE, size = 2, max.overlaps = 30)\n# \n# g + theme_graph()\n\n\n\n\nShow the code\nquantile_graph <- quantile(eigen_centrality(MC2_graph)$vector,\n         probs = seq(0, 1, 1/10)\n         )\nV(MC2_graph)$size = eigen_centrality(MC2_graph)$vector\n\nMC2_graph_aggregated <- delete_vertices(MC2_graph, V(MC2_graph)[size < quantile_graph[10]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(MC2_graph_aggregated)\n\nquantile_graph_aggregated <- quantile(V(MC2_graph_aggregated)$size, #identify top 10% of the new vertices\n         probs = seq(0, 1, 1/10)\n         )\n\n\nV(MC2_graph_aggregated)$color <- ifelse (V(MC2_graph_aggregated)$size > quantile_graph_aggregated[10], \"darkgoldenrod3\", \"azure3\") #color yellow if vertices is top 10%\nE(MC2_graph_aggregated)$color <- \"grey\"\nV(MC2_graph_aggregated)$size <- V(MC2_graph_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(MC2_graph_aggregated)$id <- ifelse (V(MC2_graph_aggregated)$size*0.065 > quantile_graph_aggregated[10],V(MC2_graph_aggregated)$id,NA)\n#label the vertices if vertices belongs to the top 10%\n\n\nplot(MC2_graph_aggregated, edge.arrow.size = 0.25, edge.arrow.mode = \"-\", \n     vertex.label = V(MC2_graph_aggregated)$id, vertex.label.cex = 0.65, \n     vertex.label.font = 1, main = \"Which company has most links to other nodes?\")\n\n\n\n\n\nHowever, a higher number of links could potentially indicate a higher level of activity, collaborations, or partnerships, which might increase the likelihood of a company undergoing name changes.\n\n\nShow the code\nset.seed (1234)\nGNC <- cluster_edge_betweenness(MC2_graph_aggregated, weights = NULL)\nV(MC2_graph_aggregated)$color <-membership(GNC)              #Plot setting specifying the coloring of vertices by community\nMC2_graph_aggregated$palette <- diverging_pal(length(GNC)) \nplot(MC2_graph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = \"-\", vertex.label = V(MC2_graph_aggregated)$id, vertex.label.cex = 0.65, vertex.label.font = 1, main = \"How many clusters within the same community?\")\n\n\n\n\n\n\n\nVisNetwork Graph\n\n\nShow the code\nedges_df <- MC2_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df <- MC2_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# Let's add a column with the group of each name. It will be useful later to color points\nnodes_df$group <- edges_df$from[match(nodes_df$id, edges_df$to)]\n\nvisNetwork(nodes_df,\n           edges_df) %>%\n  visIgraphLayout(layout = \"layout_with_fr\",\n                  smooth = FALSE,\n                  physics = FALSE) %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE,\n                         type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\n\nShow the code\nedges_df1 <- MC2_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC2_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# Perform community detection using the group edge cluster betweenness algorithm\ncommunities <- cluster_edge_betweenness(MC2_graph)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE,\n                         type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nHypothesis testing: Does types of fishing affect eigen betweenness score?\n\n\nShow the code\nMC2_edges_aggregated_r <- MC2_edges_clean_mapped %>%\n  #filter(year %in% c(2028)) %>%\n  filter(fishtype !=\"not fish\") %>%\n  group_by(source, target, fishtype, year) %>%\n  summarise(Weight = n()) %>%\n  filter(source != target) %>%\n  filter(Weight > 20) %>%\n  ungroup()\n\n# Filter rows in nodes based on matching ids in edges target and source\n\nid3 <- MC2_edges_aggregated_r %>%\n  select(source) %>%\n  rename(id = source)\nid4 <- MC2_edges_aggregated_r %>%\n  select(target) %>%\n  rename(id = target)\n\nMC2_nodes_extracted_r <- rbind(id3, id4)  %>%\n  distinct()\n\n\nMC2_nodes_extracted_r <- MC2_nodes_extracted_r %>%\n  left_join(MC2_edges_aggregated_r %>% select(target, fishtype), by = c(\"id\" = \"target\")) %>%\n  select(id, fishtype)\n\n\nMC2_graph_r <- tbl_graph(nodes = MC2_nodes_extracted_r,\n                        edges = MC2_edges_aggregated_r, \n                        directed = TRUE) \n\nMC2_graph_r \n\n\n# A tbl_graph: 5404 nodes and 4610 edges\n#\n# A directed acyclic multigraph with 4246 components\n#\n# A tibble: 5,404 × 2\n  id                                  fishtype\n  <chr>                               <chr>   \n1 1 Limited Liability Company         <NA>    \n2 1 Ltd. Liability Co Cargo           <NA>    \n3 2 Limited Liability Company         <NA>    \n4 2 Wharf S.A. de C.V. Delivery       <NA>    \n5 3 Logistics Tom yum                 <NA>    \n6 4 Limited Liability Company Seaport <NA>    \n# ℹ 5,398 more rows\n#\n# A tibble: 4,610 × 5\n   from    to fishtype     year Weight\n  <int> <int> <chr>       <dbl>  <int>\n1     1  1056 frozen fish  2034     28\n2     2  1067 crustaceans  2028     70\n3     2  1067 crustaceans  2029     59\n# ℹ 4,607 more rows\n\n\nShow the code\nV(MC2_graph_r)$size = eigen_centrality(MC2_graph_r)$vector\n\n\nMC2_graph_analysis_r <- as.data.frame(MC2_graph_r)\n\np1 <- ggbetweenstats(\n  data = MC2_graph_analysis_r,\n  x = fishtype,\n  y = size,\n  xlab = \"fishtype\",\n  ylab = \"EV Centrality \\nScore\",\n  title = \"Will betweenness score be affected by fishing type?\",\n  type = \"np\", #conduct non-parametric test\n  conf.level = 0.95,\n  mean.ci = TRUE,\n  package = \"ggsci\",\n  palette = \"default_jco\"\n) +\n  ggplot2::theme(\n    axis.title.y = element_text(angle = 0, size = 9),\n    axis.title.x = element_text(size = 9),\n    plot.title = element_text(color = \"dimgrey\", size = 12, hjust = 0.5)\n)\n\np1"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html",
    "title": "Take-home_Ex3",
    "section": "",
    "text": "With reference to Mini-Challenge 3 of VAST Challenge 2023 and by using appropriate static and interactive statistical graphics methods, I will be revealing the:\n\nUse visual analytics to identify anomalies in the business groups present in the knowledge graph.\n\n\n\n\nNetwork Analysis: Conduct network analysis on the knowledge graph to extract relevant structural properties and characteristics. This can include measures such as centrality (e.g., degree, betweenness, closeness), community detection that provide insights into the connectivity and organization of the graph.\nAnomaly Detection: Apply measures such as degree centrality in the network graph, as it counts how many edges each node has - the most degree central actor is the one with the most ties. For example, a Business Owner who owns only one business should be less suspicious than a Business Owner who owns more than three companies."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#install-and-load-the-packages",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#install-and-load-the-packages",
    "title": "Take-home_Ex3",
    "section": "Install and load the packages",
    "text": "Install and load the packages\nThe following code chunks will install and load the required packages.\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, \n               visNetwork, graphlayouts, ggforce, \n               skimr, tidytext, tidyverse, igraph, wordcloud, cluster)"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#load-the-dataset-in-json-format",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#load-the-dataset-in-json-format",
    "title": "Take-home_Ex3",
    "section": "Load the dataset in JSON format",
    "text": "Load the dataset in JSON format\nIn the code chunk below, from JSON() of jsonlite package is used to import MC3.json into R environment.\n\n\nShow the code\nMC3 <- fromJSON(\"data/MC3.json\")"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#data-wrangling",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#data-wrangling",
    "title": "Take-home_Ex3",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nExtracting the nodes and links\nThe code chunk is used to extract nodes/edges data tables from MC3 list object and save the output in a tibble data frame object called MC3_nodes and MC3_edges.\n\n\nShow the code\nMC3_nodes <- as_tibble(MC3$nodes) %>%\n  # distinct() %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id, country, type, revenue_omu, product_services)\n\nglimpse(MC3_nodes)\n\n\nRows: 27,622\nColumns: 5\n$ id               <chr> \"Jones LLC\", \"Coleman, Hall and Lopez\", \"Aqua Advance…\n$ country          <chr> \"ZH\", \"ZH\", \"Oceanus\", \"Utoporiana\", \"ZH\", \"ZH\", \"Rio…\n$ type             <chr> \"Company\", \"Company\", \"Company\", \"Company\", \"Company\"…\n$ revenue_omu      <dbl> 310612303, 162734684, 115004667, 90986413, 81466667, …\n$ product_services <chr> \"Automobiles\", \"Passenger cars, trucks, vans, and bus…\n\n\n\nmutate() and as.character() are used to convert the field data type from list to character.\nTo convert revenue_omu from list data type to numeric data type, we need to convert the values into character first by using as.character(). Then, as.numeric() will be used to convert them into numeric data type.\nselect() is used to re-organise the order of the fields.\n\n\n\nShow the code\nMC3_edges <- as_tibble(MC3$links) %>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n  summarise(weights = n()) %>%\n  filter(source != target) %>%\n  ungroup()\n\nglimpse(MC3_edges)  \n\n\nRows: 24,036\nColumns: 4\n$ source  <chr> \"1 AS Marine sanctuary\", \"1 AS Marine sanctuary\", \"1 Ltd. Liab…\n$ target  <chr> \"Christina Taylor\", \"Debbie Sanders\", \"Angela Smith\", \"Catheri…\n$ type    <chr> \"Company Contacts\", \"Beneficial Owner\", \"Beneficial Owner\", \"C…\n$ weights <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n\ndistinct() is used to ensure that there will be no duplicated records.\nmutate() and as.character() are used to convert the field data type from list to character.\ngroup_by() and summarise() are used to count the number of unique links.\nthe filter(source!=target) is to ensure that no record with similar source and target."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#exploring-the-edges-data-frame",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#exploring-the-edges-data-frame",
    "title": "Take-home_Ex3",
    "section": "Exploring the edges data frame",
    "text": "Exploring the edges data frame\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of mc3_edges tibble data frame.\n\n\nShow the code\nskim(MC3_edges)\n\n\n\nData summary\n\n\nName\nMC3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\nThe report above reveals that there is not missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display MC3_edges tibble dataframe as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(MC3_edges)\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = MC3_edges,\n       aes(x = type)) +\n  geom_bar() +\n  labs(title = \"Visualise the type variable in Edges dataframe\")  # Add the plot title\n\n\n\n\n\nThe above barplot shows the distribution of the type variable in the edge dataframe. From the two bars we can observe that in the type variable they are only two categories “Beneficial Owner”, and “Company Contacts”. Beneficial Owner formed the majority counts and is more than double of the Company Contacts.\nIn the Datatable of the Edge dataframe, we are able to identify the source variable contains company names, while the target variable contains the persons’ names. Therefore we can conclude that the type variable used to identify whether a person in the target variable belongs to the Beneficial Owner or Company Contacts."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#initial-network-visualisation-and-analysis",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#initial-network-visualisation-and-analysis",
    "title": "Take-home_Ex3",
    "section": "Initial Network Visualisation and Analysis",
    "text": "Initial Network Visualisation and Analysis\n\nBuilding network model with tidygraph\n\n\nShow the code\nid1 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid2 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(MC3_nodes, unmatched = \"drop\")\n\n\n\n\nShow the code\nMC3_graph <- tbl_graph(nodes = MC3_nodes1,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = as.factor(centrality_closeness()))\n\nMC3_graph %>%\n  filter(betweenness_centrality >= 100000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = closeness_centrality, alpha = 0.5), show.legend = FALSE) +\n  scale_size_continuous(range=c(1,10))+\n  labs(title = \"Initial Network Visualisation\") +  # Add the plot title\n  theme_graph()\n\n\n\n\n\nFrom above network graph, even though we have applied the betweenness_centrality, closeness_centrality scores as the size and color of the nodes, we only able to see nodes in the center area tend to have interlink with other nodes nearby, those nodes that located near the boundaries are have less link or only one link. Other than that there are not much insights could be generated by the graph."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#exploring-the-nodes-data-frame",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#exploring-the-nodes-data-frame",
    "title": "Take-home_Ex3",
    "section": "Exploring the nodes data frame",
    "text": "Exploring the nodes data frame\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of MC3_nodes tibble data frame.\n\n\nShow the code\nskim(MC3_nodes)\n\n\n\nData summary\n\n\nName\nMC3_nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\nThe report above reveals that there is no missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display mc3_nodes tibble data frame as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(MC3_nodes)\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = MC3_nodes,\n       aes(x = type)) +\n  geom_bar() +\n  labs(title = \"Visualise the type variable in Nodes dataframe\")  # Add the plot title\n\n\n\n\n\nThe above barplot shows the distribution of the type variable in the node dataframe. From the above three bars we can observe that in the type variable they have three categories which are “Beneficial Owner”, “Company”, and “Company Contacts”. The type variable used to identify the id belongs to which categories."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#text-sensing-with-tidytext",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#text-sensing-with-tidytext",
    "title": "Take-home_Ex3",
    "section": "Text Sensing with tidytext",
    "text": "Text Sensing with tidytext\nIn this section, you will learn how to perform basic text sensing using appropriate functions of tidytext package.\n\nSimple word count\nThe code chunk below calculates number of times the word fish appeared in the field product_services.\n\n\nShow the code\nMC3_nodes %>%\n  mutate(n_fish = str_count(product_services, \"fish\"))\n\n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   <chr>                       <chr>   <chr>       <dbl> <chr>             <int>\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows\n\n\n\n\nShow the code\nMC3_nodes %>%\n  mutate(n_seafood = str_count(product_services, \"seafood\"))\n\n\n# A tibble: 27,622 × 6\n   id                       country type  revenue_omu product_services n_seafood\n   <chr>                    <chr>   <chr>       <dbl> <chr>                <int>\n 1 Jones LLC                ZH      Comp…  310612303. Automobiles              0\n 2 Coleman, Hall and Lopez  ZH      Comp…  162734684. Passenger cars,…         0\n 3 Aqua Advancements Sashi… Oceanus Comp…  115004667. Holding firm wh…         0\n 4 Makumba Ltd. Liability … Utopor… Comp…   90986413. Car service, ca…         0\n 5 Taylor, Taylor and Farr… ZH      Comp…   81466667. Fully electric …         0\n 6 Harmon, Edwards and Bat… ZH      Comp…   75070435. Discount superm…         0\n 7 Punjab s Marine conserv… Riodel… Comp…   72167572. Beef, pork, chi…         0\n 8 Assam   Limited Liabili… Utopor… Comp…   72162317. Power and Gas s…         0\n 9 Ianira Starfish Sagl Im… Rio Is… Comp…   68832979. Light commercia…         0\n10 Moran, Lewis and Jimenez ZH      Comp…   65592906. Automobiles, tr…         0\n# ℹ 27,612 more rows\n\n\n\n\nTokenisation\nThe word tokenisation have different meaning in different scientific domains. In text sensing, tokenisation is the process of breaking up a given text into units called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.\nIn the code chunk below, unnest_token() of tidytext is used to split text in product_services field into words.\n\n\nShow the code\ntoken_nodes <- MC3_nodes %>%\n  unnest_tokens(word, product_services)\n\n\nThe two basic arguments to unnest_tokens() used here are column names. First we have the output column name that will be created as the text is unnested into it (word, in this case), and then the input column that the text comes from (product_services, in this case).\n\n\n\n\n\n\nNote\n\n\n\n\nBy default, punctuation has been stripped. (Use the to_lower = FALSE argument to turn off this behavior).\nBy default, unnest_tokens() converts the tokens to lowercase, which makes them easier to compare or combine with other datasets. (Use the to_lower = FALSE argument to turn off this behavior).\n\n\n\nNow we can visualise the words extracted by using the code chunk below.\n\n\nShow the code\ntoken_nodes %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y=n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n    labs(x = \"Count\",\n         y = \"Unique words\",\n         title = \"Count of unique words found in product_services field\")\n\n\n\n\n\nThe bar chart reveals that the unique words contains some words that may not be useful to use. For instance “a” and “to”. In the word of text mining we call those words stop words. You want to remove these words from your analysis as they are fillers used to compose a sentence.\n\n\nRemoving stopwords\nThe tidytext package has a function called stop_words that will help us clean up stop words.\n\n\nShow the code\nstopwords_removed <- token_nodes %>%\n  anti_join(stop_words)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nLoad the stop_words data included with tidytext. This data is simply a list of words that you may want to remove in a natural language analysis.\nThen anti_join() of dplyr package is used to remove all stop words from the analysis.\n\n\n\nWe can visualise the words extracted again.\n\n\nShow the code\nstopwords_removed %>%\n  count(word, sort = TRUE) %>%\n  top_n(20) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y=n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n    labs(x = \"Count\",\n         y = \"Unique words\",\n         title = \"Count of unique words found in product_services field (removed stopwords)\")\n\n\n\n\n\n\n\nVisulize keyword in WordCloud (exclude 0, unknown and character)\n\n\nShow the code\ndf_wordcloud <- stopwords_removed\n\n# Count the frequency of each word\nword_frequency <- df_wordcloud %>%\n  group_by(word) %>%\n  filter(!word %in% c(\"character\", \"0\", \"unknown\")) %>%\n  summarise(freq = n()) %>%\n  arrange(desc(freq))\n\n# Create a word cloud\nset.seed(1234)  # for reproducibility of random colors\nwordcloud(words = word_frequency$word, freq = word_frequency$freq, min.freq = 10\n          ,\n          max.words=200, random.order=FALSE, rot.per=0.35, \n          colors=brewer.pal(8, \"Dark2\"))"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#visualize-different-keyword",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#visualize-different-keyword",
    "title": "Take-home_Ex3",
    "section": "Visualize different keyword",
    "text": "Visualize different keyword\n\nproductsfish and seafoodfrozen\n\n\n\n\nShow the code\ndf <- stopwords_removed\n\n# Filter the data frame\ndf_extracted <- df %>%\n  filter(str_detect(word, pattern = \"products\"))\n\n# Remove duplicate IDs\ndf_extracted_distinct <- df_extracted %>%\n  distinct(id, keep_all = TRUE)\n\n# Network visualisation for products related companies \n\nid3 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid4 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes_extracted <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(df_extracted_distinct, unmatched = \"drop\")\n\nMC3_graph_extracted <- tbl_graph(nodes = MC3_nodes_extracted,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness()\n         ) %>%\n  filter(betweenness_centrality >= quantile(betweenness_centrality, 0.99))\n\n\n#create Visnetwork graph\nedges_df1 <- MC3_graph_extracted %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC3_graph_extracted %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# # Convert the graph to undirected\n# MC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph_extracted)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf <- stopwords_removed\n\n# Filter the data frame\ndf_extracted <- df %>%\n  filter(str_detect(word, pattern = \"fish\") | str_detect(word, pattern = \"seafood\"))\n\n# Remove duplicate IDs\ndf_extracted_distinct <- df_extracted %>%\n  distinct(id, keep_all = TRUE)\n\n# Network visualisation for fish and seafood related companies \n\nid3 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid4 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes_extracted <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(df_extracted_distinct, unmatched = \"drop\")\n\nMC3_graph_extracted <- tbl_graph(nodes = MC3_nodes_extracted,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness()\n         ) %>%\n  filter(betweenness_centrality >= quantile(betweenness_centrality, 0.99))\n\n\n#create Visnetwork graph\nedges_df1 <- MC3_graph_extracted %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC3_graph_extracted %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# # Convert the graph to undirected\n# MC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph_extracted)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_graphopt\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf <- stopwords_removed\n\n# Filter the data frame\ndf_extracted <- df %>%\n  filter(str_detect(word, pattern = \"frozen\") )\n\n# Remove duplicate IDs\ndf_extracted_distinct <- df_extracted %>%\n  distinct(id, keep_all = TRUE)\n\n# Network visualisation for products related companies \n\nid3 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid4 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes_extracted <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(df_extracted_distinct, unmatched = \"drop\")\n\nMC3_graph_extracted <- tbl_graph(nodes = MC3_nodes_extracted,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  filter(betweenness_centrality >= quantile(betweenness_centrality, 0.99))\n\n\n#create Visnetwork graph\nedges_df1 <- MC3_graph_extracted %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC3_graph_extracted %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# # Convert the graph to undirected\n# MC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph_extracted)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html",
    "title": "Take-home_Ex3",
    "section": "",
    "text": "With reference to Mini-Challenge 3 of VAST Challenge 2023 and by using appropriate static and interactive statistical graphics methods, I will be revealing the:"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#install-and-load-the-packages",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#install-and-load-the-packages",
    "title": "Take-home_Ex3",
    "section": "Install and load the packages",
    "text": "Install and load the packages\nThe following code chunks will install and load the required packages.\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, \n               visNetwork, graphlayouts, ggforce, \n               skimr, tidytext, tidyverse, igraph, wordcloud, RColorBrewer, stringr, cluster)"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#load-the-dataset-in-json-format",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#load-the-dataset-in-json-format",
    "title": "Take-home_Ex3",
    "section": "Load the dataset in JSON format",
    "text": "Load the dataset in JSON format\nIn the code chunk below, from JSON() of jsonlite package is used to import MC3.json into R environment.\n\n\nShow the code\nMC3 <- fromJSON(\"data/MC3.json\")"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#data-wrangling",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#data-wrangling",
    "title": "Take-home_Ex3",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nExtracting the nodes and links\nThe code chunk is used to extract nodes/edges data tables from MC3 list object and save the output in a tibble data frame object called MC3_nodes and MC3_edges.\n\n\nShow the code\nMC3_nodes <- as_tibble(MC3$nodes) %>%\n  # distinct() %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id, country, type, revenue_omu, product_services)\n\nglimpse(MC3_nodes)\n\n\nRows: 27,622\nColumns: 5\n$ id               <chr> \"Jones LLC\", \"Coleman, Hall and Lopez\", \"Aqua Advance…\n$ country          <chr> \"ZH\", \"ZH\", \"Oceanus\", \"Utoporiana\", \"ZH\", \"ZH\", \"Rio…\n$ type             <chr> \"Company\", \"Company\", \"Company\", \"Company\", \"Company\"…\n$ revenue_omu      <dbl> 310612303, 162734684, 115004667, 90986413, 81466667, …\n$ product_services <chr> \"Automobiles\", \"Passenger cars, trucks, vans, and bus…\n\n\n\nmutate() and as.character() are used to convert the field data type from list to character.\nTo convert revenue_omu from list data type to numeric data type, we need to convert the values into character first by using as.character(). Then, as.numeric() will be used to convert them into numeric data type.\nselect() is used to re-organise the order of the fields.\n\n\n\nShow the code\nMC3_edges <- as_tibble(MC3$links) %>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n  summarise(weights = n()) %>%\n  filter(source != target) %>%\n  ungroup()\n\nglimpse(MC3_edges)  \n\n\nRows: 24,036\nColumns: 4\n$ source  <chr> \"1 AS Marine sanctuary\", \"1 AS Marine sanctuary\", \"1 Ltd. Liab…\n$ target  <chr> \"Christina Taylor\", \"Debbie Sanders\", \"Angela Smith\", \"Catheri…\n$ type    <chr> \"Company Contacts\", \"Beneficial Owner\", \"Beneficial Owner\", \"C…\n$ weights <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n\ndistinct() is used to ensure that there will be no duplicated records.\nmutate() and as.character() are used to convert the field data type from list to character.\ngroup_by() and summarise() are used to count the number of unique links.\nthe filter(source!=target) is to ensure that no record with similar source and target."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#exploring-the-edges-data-frame",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#exploring-the-edges-data-frame",
    "title": "Take-home_Ex3",
    "section": "Exploring the edges data frame",
    "text": "Exploring the edges data frame\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of mc3_edges tibble data frame.\n\n\nShow the code\nskim(MC3_edges)\n\n\n\nData summary\n\n\nName\nMC3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\nThe report above reveals that there is not missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display MC3_edges tibble dataframe as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(MC3_edges)\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = MC3_edges,\n       aes(x = type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#initial-network-visualisation-and-analysis",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#initial-network-visualisation-and-analysis",
    "title": "Take-home_Ex3",
    "section": "Initial Network Visualisation and Analysis",
    "text": "Initial Network Visualisation and Analysis\n\nBuilding network model with tidygraph\n\n\nShow the code\nid1 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid2 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(MC3_nodes, unmatched = \"drop\")\n\n\n\n\nShow the code\nMC3_graph <- tbl_graph(nodes = MC3_nodes1,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = as.factor(centrality_closeness())) %>%\n  mutate(degree_centrality = centrality_degree()) %>%\n  filter(betweenness_centrality >= 30000) %>%\n  filter(degree_centrality >= 3)\n\n\n\n\nShow the code\n# Calculate the degrees of each node\ndegrees <- degree(MC3_graph)\nset.seed (1234)\nMC3_graph %>%\n  # filter(betweenness_centrality >= 100000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(size = betweenness_centrality,\n                      color = closeness_centrality,\n                      alpha = 0.5), show.legend = FALSE) +\n  geom_node_text(aes(label = ifelse(degrees > 3, as.character(id), \"\")), size = 2) +  # Add node labels\n  scale_size_continuous(range = c(1, 10)) +\n  theme_graph()\n\n\n\n\n\n\n\nShow the code\nMC3_graph <- tbl_graph(nodes = MC3_nodes1,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  filter(betweenness_centrality >= 10000)\n\nquantile_graph <- quantile(eigen_centrality(MC3_graph)$vector,\n         probs = seq(0, 1, 1/10)\n         )\nV(MC3_graph)$size = eigen_centrality(MC3_graph)$vector\n\nMC3_graph_aggregated <- delete_vertices(MC3_graph, V(MC3_graph)[size < quantile_graph[10]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(MC3_graph_aggregated)\n\nquantile_graph_aggregated <- quantile(V(MC3_graph_aggregated)$size, #identify top 20% of the new vertices\n         probs = seq(0, 1, 1/10)\n         )\n\n\nV(MC3_graph_aggregated)$color <- ifelse (V(MC3_graph_aggregated)$size > quantile_graph_aggregated[10], \"darkgoldenrod3\", \"azure3\") #color yellow if vertices is top 20%\nE(MC3_graph_aggregated)$color <- \"grey\"\nV(MC3_graph_aggregated)$size <- V(MC3_graph_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(MC3_graph_aggregated)$id <- ifelse (V(MC3_graph_aggregated)$size*0.065 > quantile_graph_aggregated[10],V(MC3_graph_aggregated)$id,NA)\n#label the vertices if vertices belongs to the top 20%\n\n\nplot(MC3_graph_aggregated, edge.arrow.size = 0.25, edge.arrow.mode = \"-\", \n     vertex.label = V(MC3_graph_aggregated)$id, vertex.label.cex = 0.65, \n     vertex.label.font = 1, main = \"Which companies are having more edges to other nodes?\")"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#exploring-the-nodes-data-frame",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#exploring-the-nodes-data-frame",
    "title": "Take-home_Ex3",
    "section": "Exploring the nodes data frame",
    "text": "Exploring the nodes data frame\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of MC3_nodes tibble data frame.\n\n\nShow the code\nskim(MC3_nodes)\n\n\n\nData summary\n\n\nName\nMC3_nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\nThe report above reveals that there is no missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display mc3_nodes tibble data frame as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(MC3_nodes)\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = MC3_nodes,\n       aes(x = type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#text-sensing-with-tidytext",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#text-sensing-with-tidytext",
    "title": "Take-home_Ex3",
    "section": "Text Sensing with tidytext",
    "text": "Text Sensing with tidytext\nIn this section, you will learn how to perform basic text sensing using appropriate functions of tidytext package.\n\nSimple word count\nThe code chunk below calculates number of times the word fish appeared in the field product_services.\n\n\nShow the code\nMC3_nodes %>%\n  mutate(n_fish = str_count(product_services, \"fish\"))\n\n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   <chr>                       <chr>   <chr>       <dbl> <chr>             <int>\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows\n\n\n\n\nShow the code\nMC3_nodes %>%\n  mutate(n_seafood = str_count(product_services, \"seafood\"))\n\n\n# A tibble: 27,622 × 6\n   id                       country type  revenue_omu product_services n_seafood\n   <chr>                    <chr>   <chr>       <dbl> <chr>                <int>\n 1 Jones LLC                ZH      Comp…  310612303. Automobiles              0\n 2 Coleman, Hall and Lopez  ZH      Comp…  162734684. Passenger cars,…         0\n 3 Aqua Advancements Sashi… Oceanus Comp…  115004667. Holding firm wh…         0\n 4 Makumba Ltd. Liability … Utopor… Comp…   90986413. Car service, ca…         0\n 5 Taylor, Taylor and Farr… ZH      Comp…   81466667. Fully electric …         0\n 6 Harmon, Edwards and Bat… ZH      Comp…   75070435. Discount superm…         0\n 7 Punjab s Marine conserv… Riodel… Comp…   72167572. Beef, pork, chi…         0\n 8 Assam   Limited Liabili… Utopor… Comp…   72162317. Power and Gas s…         0\n 9 Ianira Starfish Sagl Im… Rio Is… Comp…   68832979. Light commercia…         0\n10 Moran, Lewis and Jimenez ZH      Comp…   65592906. Automobiles, tr…         0\n# ℹ 27,612 more rows\n\n\n\n\nTokenisation\nThe word tokenisation have different meaning in different scientific domains. In text sensing, tokenisation is the process of breaking up a given text into units called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.\nIn the code chunk below, unnest_token() of tidytext is used to split text in product_services field into words.\n\n\nShow the code\ntoken_nodes <- MC3_nodes %>%\n  unnest_tokens(word, product_services)\n\n\nThe two basic arguments to unnest_tokens() used here are column names. First we have the output column name that will be created as the text is unnested into it (word, in this case), and then the input column that the text comes from (product_services, in this case).\n\n\n\n\n\n\nNote\n\n\n\n\nBy default, punctuation has been stripped. (Use the to_lower = FALSE argument to turn off this behavior).\nBy default, unnest_tokens() converts the tokens to lowercase, which makes them easier to compare or combine with other datasets. (Use the to_lower = FALSE argument to turn off this behavior).\n\n\n\nNow we can visualise the words extracted by using the code chunk below.\n\n\nShow the code\ntoken_nodes %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y=n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n    labs(x = \"Count\",\n         y = \"Unique words\",\n         title = \"Count of unique words found in product_services field\")\n\n\n\n\n\nThe bar chart reveals that the unique words contains some words that may not be useful to use. For instance “a” and “to”. In the word of text mining we call those words stop words. You want to remove these words from your analysis as they are fillers used to compose a sentence.\n\n\nRemoving stopwords\nThe tidytext package has a function called stop_words that will help us clean up stop words.\n\n\nShow the code\nstopwords_removed <- token_nodes %>%\n  anti_join(stop_words)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nLoad the stop_words data included with tidytext. This data is simply a list of words that you may want to remove in a natural language analysis.\nThen anti_join() of dplyr package is used to remove all stop words from the analysis.\n\n\n\nWe can visualise the words extracted again.\n\n\nShow the code\nstopwords_removed %>%\n  count(word, sort = TRUE) %>%\n  top_n(20) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y=n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n    labs(x = \"Count\",\n         y = \"Unique words\",\n         title = \"Count of unique words found in product_services field (removed stopwords)\")\n\n\n\n\n\n\n\nShow the code\nglimpse(stopwords_removed)\n\n\nRows: 88,505\nColumns: 5\n$ id          <chr> \"Jones LLC\", \"Coleman, Hall and Lopez\", \"Coleman, Hall and…\n$ country     <chr> \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"ZH\", \"Oceanus\", \"Oceanus\", …\n$ type        <chr> \"Company\", \"Company\", \"Company\", \"Company\", \"Company\", \"Co…\n$ revenue_omu <dbl> 310612303, 162734684, 162734684, 162734684, 162734684, 162…\n$ word        <chr> \"automobiles\", \"passenger\", \"cars\", \"trucks\", \"vans\", \"bus…\n\n\n\n\nShow the code\nedges_df <- MC3_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df <- MC3_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n # Convert the graph to undirected\nMC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df, edges_df) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\n\nShow the code\ndf_temp <- stopwords_removed %>%\n  select(id, word) %>%\n  rename(label = id)\n\nmerged_df <- merge(nodes_df, df_temp, by = \"label\")\n\nglimpse(merged_df)\n\n\nRows: 5,132\nColumns: 4\n$ label <chr> \"4 N.V. Marine biology\", \"7 GmbH & Co. KG\", \"7 GmbH & Co. KG\", \"…\n$ id    <int> 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ group <dbl> 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ word  <chr> \"unknown\", \"manufacture\", \"flatware\", \"pans\", \"plated\", \"kitchen…\n\n\nShow the code\ntop_words <- merged_df %>%\n  count(group, word, sort = TRUE) %>%\n  group_by(group) %>%\n  top_n(n = 1)  # Select the top frequent word in each group\n\nggplot(top_words, aes(x = group, y = n, fill = word)) +\n  geom_col() +\n  labs(x = \"Group\", y = \"Frequency\", fill = \"Word\") +\n  theme_minimal()\n\n\n\n\n\n\n\nShow the code\ndf_wordcloud <- stopwords_removed\n\n# Count the frequency of each word\nword_frequency <- df_wordcloud %>%\n  group_by(word) %>%\n  filter(!word %in% c(\"character\", \"0\", \"unknown\")) %>%\n  summarise(freq = n()) %>%\n  arrange(desc(freq))\n\n# Create a word cloud\nset.seed(1234)  # for reproducibility of random colors\nwordcloud(words = word_frequency$word, freq = word_frequency$freq, min.freq = 10\n          ,\n          max.words=200, random.order=FALSE, rot.per=0.35, \n          colors=brewer.pal(8, \"Dark2\"))"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#visualize-different-keyword",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3_old.html#visualize-different-keyword",
    "title": "Take-home_Ex3",
    "section": "Visualize different keyword",
    "text": "Visualize different keyword\n\nproductsfish and seafoodfrozen\n\n\n\n\nShow the code\ndf <- stopwords_removed\n\n# Filter the data frame\ndf_extracted <- df %>%\n  filter(str_detect(word, pattern = \"products\"))\n\n# Remove duplicate IDs\ndf_extracted_distinct <- df_extracted %>%\n  distinct(id, keep_all = TRUE)\n\n# Network visualisation for products related companies \n\nid3 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid4 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes_extracted <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(df_extracted_distinct, unmatched = \"drop\")\n\nMC3_graph_extracted <- tbl_graph(nodes = MC3_nodes_extracted,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness()\n         ) %>%\n  filter(betweenness_centrality >= quantile(betweenness_centrality, 0.99))\n\n\n#create Visnetwork graph\nedges_df1 <- MC3_graph_extracted %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC3_graph_extracted %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# # Convert the graph to undirected\n# MC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph_extracted)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf <- stopwords_removed\n\n# Filter the data frame\ndf_extracted <- df %>%\n  filter(str_detect(word, pattern = \"fish\") | str_detect(word, pattern = \"seafood\"))\n\n# Remove duplicate IDs\ndf_extracted_distinct <- df_extracted %>%\n  distinct(id, keep_all = TRUE)\n\n# Network visualisation for fish and seafood related companies \n\nid3 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid4 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes_extracted <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(df_extracted_distinct, unmatched = \"drop\")\n\nMC3_graph_extracted <- tbl_graph(nodes = MC3_nodes_extracted,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness()\n         ) %>%\n  filter(betweenness_centrality >= quantile(betweenness_centrality, 0.99))\n\n\n#create Visnetwork graph\nedges_df1 <- MC3_graph_extracted %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC3_graph_extracted %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# # Convert the graph to undirected\n# MC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph_extracted)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_graphopt\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf <- stopwords_removed\n\n# Filter the data frame\ndf_extracted <- df %>%\n  filter(str_detect(word, pattern = \"frozen\") )\n\n# Remove duplicate IDs\ndf_extracted_distinct <- df_extracted %>%\n  distinct(id, keep_all = TRUE)\n\n# Network visualisation for products related companies \n\nid3 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid4 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes_extracted <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(df_extracted_distinct, unmatched = \"drop\")\n\nMC3_graph_extracted <- tbl_graph(nodes = MC3_nodes_extracted,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  filter(betweenness_centrality >= quantile(betweenness_centrality, 0.99))\n\n\n#create Visnetwork graph\nedges_df1 <- MC3_graph_extracted %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df1 <- MC3_graph_extracted %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# # Convert the graph to undirected\n# MC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph_extracted)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df1$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df1, edges_df1) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf <- stopwords_removed\n\n# Filter the data frame\ndf_extracted <- df %>%\n  filter(str_detect(word, pattern = \"fish\") | str_detect(word, pattern = \"seafood\"))\n\n# Remove duplicate IDs\ndf_extracted_distinct <- df_extracted %>%\n  distinct(id, keep_all = TRUE)\n\n\nid3 <- MC3_edges %>%\n  select(source) %>%\n  rename(id = source)\n\nid4 <- MC3_edges %>%\n  select(id = target)\n\nMC3_nodes_extracted <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(df_extracted_distinct, unmatched = \"drop\")\n\nMC3_graph_extracted <- tbl_graph(nodes = MC3_nodes_extracted,\n                       edges = MC3_edges,\n                       directed = FALSE)\n\nV(MC3_graph_extracted)$betweenness <- betweenness(MC3_graph_extracted, directed = F)\n\n\nplot(MC3_graph_extracted,\n     vertex.label.cex = .6, \n     vertex.label.color = \"black\", \n     vertex.size = V(MC3_graph_extracted)$betweenness/max(V(MC3_graph_extracted)$betweenness) * 50)"
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#network-visulization-of-nodes-with-more-than-3-edges.",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#network-visulization-of-nodes-with-more-than-3-edges.",
    "title": "Take-home_Ex3",
    "section": "Network Visulization of nodes with more than 3 edges.",
    "text": "Network Visulization of nodes with more than 3 edges.\n\n\nShow the code\nMC3_graph <- tbl_graph(nodes = MC3_nodes1,\n                       edges = MC3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = as.factor(centrality_closeness())) %>%\n  filter(betweenness_centrality >= 100000)\n\n         \n# Calculate the degrees of each node\ndegrees <- degree(MC3_graph)\nset.seed (1234)\n\nMC3_graph %>%\n  # filter(betweenness_centrality >= 100000) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(size = betweenness_centrality,\n                      color = closeness_centrality,\n                      alpha = 0.5), show.legend = FALSE) +\n  geom_node_text(aes(label = ifelse(degrees > 3, as.character(id), \"\")), size = 2) +  # Add node labels\n  scale_size_continuous(range = c(1, 10)) +\n  labs(title = \"Network Visualization with Betweenness centrality \\nabove 10000 and degree above 3\") +  # Add the plot title\n  theme_graph()\n\n\n\n\n\nIn above network graph, I had to use a filter to exclude betweenness_centrality score which are less than 100000 in order to reduce the amount of nodes to be displayed in the graph. Here, the nodes with more than 3 link will be shown with label name.\nNoting that majority of the nodes displayed with label names are companies, however we noticed among the Beneficial Owner displayed, some Beneficial owner’ last name appeared to be the same, eg. John Smith, Jennifer Smith, Amy Williams, and John Willams. It seems the personals with the same last name could potentially coming from the same family, which make them a bit suspicious than others."
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#interactive-network-visulizing-in-visnetwork",
    "href": "Take-home_Exercise/Take-home_Ex3/Take-home_Ex3.html#interactive-network-visulizing-in-visnetwork",
    "title": "Take-home_Ex3",
    "section": "Interactive Network Visulizing in VisNetwork",
    "text": "Interactive Network Visulizing in VisNetwork\n\n\nShow the code\nedges_df <- MC3_graph %>%\n  activate(edges) %>%\n  as.tibble()\n\nnodes_df <- MC3_graph %>%\n  activate(nodes) %>%\n  as.tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n# Convert the graph to undirected\n# MC3_graph_undirected <- as.undirected(MC3_graph)\n\n# Perform community detection using the Louvain algorithm on the undirected graph\ncommunities <- cluster_louvain(MC3_graph)\n\n# Get the cluster membership of each node\nmembership <- membership(communities)\n\n# Add the cluster membership information to the nodes data frame\nnodes_df$group <- membership\n\n# Plot the graph with clustered nodes using visNetwork\nvisNetwork(nodes_df, edges_df) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE, type = \"curvedCW\"), \n           color = list(highlight = \"lightgray\")) %>%\n  visOptions(highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE, labelOnly = TRUE),\n             nodesIdSelection = TRUE,\n             selectedBy = \"group\") %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\n\n\n\nUtilze the groups created by community cluster detection, select top frequent keyword in each group\n\n\nShow the code\ndf_temp <- stopwords_removed %>%\n  select(id, word) %>%\n  rename(label = id)\n\nmerged_df <- merge(nodes_df, df_temp, by = \"label\")\n\nglimpse(merged_df)\n\n\nRows: 1,841\nColumns: 4\n$ label <chr> \"8 SE Marine life\", \"8 SE Marine life\", \"8 SE Marine life\", \"Ada…\n$ id    <int> 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 6…\n$ group <dbl> 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5…\n$ word  <chr> \"gloves\", \"products\", \"niche\", \"frozen\", \"octopus\", \"cephalopod\"…\n\n\nShow the code\ntop_words <- merged_df %>%\n  count(group, word, sort = TRUE) %>%\n  group_by(group) %>%\n  top_n(n = 1)  # Select the top frequent word in each group\n\nggplot(top_words, aes(x = group, y = n, fill = word)) +\n  geom_col() +\n  labs(x = \"Group\", y = \"Frequency\", fill = \"Word\") +\n  theme_minimal()"
  }
]